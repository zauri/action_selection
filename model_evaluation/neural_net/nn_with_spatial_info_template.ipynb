{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8da2a4b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from fastDamerauLevenshtein import damerauLevenshtein\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
    "from tensorflow.keras import layers\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f06a6ff",
   "metadata": {},
   "source": [
    "## 1. Read + prepare data\n",
    "Data is expected to be transformed into a single-step version using the `transform_data_to_single_step_workflow.py` script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49e7518e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/single_step_df_ints_2022-10-11_encoded.csv', header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94fb5be",
   "metadata": {},
   "source": [
    "Float columns: Fill NAs with -99."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52fca39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "float_cols = df.select_dtypes(include=['float64']).columns\n",
    "df.loc[:, float_cols] = df.loc[:, float_cols].fillna(-99)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c62c48",
   "metadata": {},
   "source": [
    "Object columns: Fill NAs with empty string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51c3d424",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.select_dtypes(include=['object'])\n",
    "for col in cols.columns.values:\n",
    "    df[col] = df[col].fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218b6bbd",
   "metadata": {},
   "source": [
    "Show value counts for target to check if all classes have more than one instance (required for stratisfied shuffle split)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8e9acc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "p    188\n",
       "k    162\n",
       "g    160\n",
       "f    157\n",
       "c    148\n",
       "s    134\n",
       "b     78\n",
       "w     74\n",
       "o     73\n",
       "a     72\n",
       "r     47\n",
       "d     27\n",
       "h     27\n",
       "t     22\n",
       "e     22\n",
       "z     21\n",
       "m     13\n",
       "n      9\n",
       "x      2\n",
       "i      1\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()\n",
    "df[:1437]['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0c0f90",
   "metadata": {},
   "source": [
    "Remove row with class that only occurs once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af2bd3d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "727"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_drop = df['target'].loc[df['target'] == 'i'].index[0]\n",
    "index_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3401a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_of_sequences = len(df[df['input'] == '<start>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16af1823",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df.drop(index=[index_to_drop], axis=0)\n",
    "df_new.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d9d11d",
   "metadata": {},
   "source": [
    "Use stratisfied shuffle split to generate training and test set. The dataframe is cut at index 1436 here to only use the table setting data for training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5491f1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = StratifiedShuffleSplit(n_splits=10, test_size=0.3, random_state=42)\n",
    "\n",
    "for train_index, test_index in split.split(df_new[:1436], df_new[:1436]['target']):\n",
    "    strat_train = df_new.loc[train_index]\n",
    "    strat_test_val = df_new.loc[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c7db30",
   "metadata": {},
   "source": [
    "Split test data into test and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11eba3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_test_val = len(strat_test_val)//2\n",
    "\n",
    "strat_test = strat_test_val[:split_test_val]\n",
    "strat_val = strat_test_val[split_test_val:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aaa271e",
   "metadata": {},
   "source": [
    "Generate list of labels to pass to MultiLabelBinarizer so there's the same number of classes for all datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ead4a95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df_new['target'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce71230e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f4e934",
   "metadata": {},
   "source": [
    "## 2. Create train, test, validation data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e8da447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataframe, labels, shuffle=True, batch_size=32):\n",
    "    df = dataframe.copy()\n",
    "    labels_ds = df.pop('target')\n",
    "    encoder = MultiLabelBinarizer(classes=labels)\n",
    "    encoded_labels = encoder.fit_transform(labels_ds)\n",
    "    \n",
    "    df = {key: value[:, tf.newaxis] for key, value in df.items()}\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(df), encoded_labels))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=len(dataframe))\n",
    "    \n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(batch_size)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e6e6001",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "416e6d06",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_86683/1510453973.py:7: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  df = {key: value[:, tf.newaxis] for key, value in df.items()}\n",
      "2023-08-08 12:07:29.428005: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-08 12:07:29.460784: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-08 12:07:29.460923: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-08 12:07:29.461463: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-08 12:07:29.461829: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-08 12:07:29.461955: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-08 12:07:29.462066: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-08 12:07:29.849696: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-08 12:07:29.849860: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-08 12:07:29.850025: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-08 12:07:29.850124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5989 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1070 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "train_ds = create_dataset(strat_train, labels, batch_size=batch_size)\n",
    "val_ds = create_dataset(strat_val, labels, shuffle=False, batch_size=batch_size)\n",
    "test_ds = create_dataset(strat_test, labels, shuffle=False, batch_size=batch_size);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfccf05",
   "metadata": {},
   "source": [
    "## 3. Define functions to create layers and input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06f4db47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalization_layer(name, dataset):\n",
    "  # create a normalization layer for the feature\n",
    "    normalizer = layers.Normalization(axis=None)\n",
    "\n",
    "  # prepare a dataset that only yields the feature\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "\n",
    "  # learn the statistics of the data\n",
    "    normalizer.adapt(feature_ds)\n",
    "    \n",
    "    return normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "597f7ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_encoding_layer(name, dataset, dtype, max_tokens=None):\n",
    "    if dtype == 'string':\n",
    "        index = layers.StringLookup(max_tokens=max_tokens)\n",
    "    else:\n",
    "        index = layers.IntegerLookup(max_tokens=max_tokens)\n",
    "        \n",
    "    # prepare tf.data.Dataset that only yields the feature    \n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    \n",
    "    # learn set of possible values and assign fixed int index\n",
    "    index.adapt(feature_ds)\n",
    "    \n",
    "    # encode int indices\n",
    "    encoder = layers.CategoryEncoding(num_tokens=index.vocabulary_size())\n",
    "    \n",
    "    # apply multi-hot encoding to indices\n",
    "    # lambda function captures the layer to include them in Keras functional models later\n",
    "    return lambda feature: encoder(index(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ce78468",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_data(dataframe):\n",
    "    all_inputs = []\n",
    "    encoded_features = []\n",
    "    \n",
    "    for header in dataframe.columns:\n",
    "        # numerical features\n",
    "        if 'coord' in header or 'already' in header:\n",
    "            numeric_col = tf.keras.Input(shape=(1,), name=header)\n",
    "            normalization_layer = get_normalization_layer(header, train_ds)\n",
    "            encoded_numeric_col = normalization_layer(numeric_col)\n",
    "            all_inputs.append(numeric_col)\n",
    "            encoded_features.append(encoded_numeric_col)\n",
    "        \n",
    "        # categorical features\n",
    "        elif 'containment' in header or 'food' in header or 'mid' in header or \\\n",
    "        'strong' in header:\n",
    "            categorical_col = tf.keras.Input(shape=(1,), name=header, dtype='int64')\n",
    "            encoding_layer = get_category_encoding_layer(name=header,\n",
    "                                                        dataset=train_ds,\n",
    "                                                        dtype='int64')\n",
    "            encoded_categorical_col = encoding_layer(categorical_col)\n",
    "            all_inputs.append(categorical_col)\n",
    "            encoded_features.append(encoded_categorical_col)\n",
    "            \n",
    "        elif header == 'input':\n",
    "            categorical_col = tf.keras.Input(shape=(1,), name='input', dtype='string')\n",
    "            encoding_layer = get_category_encoding_layer(name='input',\n",
    "                                                        dataset=train_ds,\n",
    "                                                        dtype='string')\n",
    "            encoded_categorical_col = encoding_layer(categorical_col)\n",
    "            all_inputs.append(categorical_col)\n",
    "            encoded_features.append(encoded_categorical_col)\n",
    "            \n",
    "    return all_inputs, encoded_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2cef52",
   "metadata": {},
   "source": [
    "## 4. Create and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d333498",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_inputs, encoded_features = create_input_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2de5cf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5caa2ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = tf.keras.layers.concatenate(encoded_features)\n",
    "x = tf.keras.layers.Dense(512, activation=\"relu\")(all_features)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(256, activation=\"relu\")(all_features)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "output = tf.keras.layers.Dense(len(labels))(x)\n",
    "\n",
    "model = tf.keras.Model(all_inputs, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1736d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9dee9ed0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "8/8 [==============================] - 12s 633ms/step - loss: 3.2333 - accuracy: 0.1144 - val_loss: 15577.4580 - val_accuracy: 0.2083\n",
      "Epoch 2/300\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 2.5568 - accuracy: 0.1751 - val_loss: 15611.1729 - val_accuracy: 0.2130\n",
      "Epoch 3/300\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 2.3916 - accuracy: 0.2000 - val_loss: 15490.7266 - val_accuracy: 0.1991\n",
      "Epoch 4/300\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 2.2532 - accuracy: 0.2299 - val_loss: 15001.9697 - val_accuracy: 0.3426\n",
      "Epoch 5/300\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 2.1739 - accuracy: 0.2169 - val_loss: 16203.2803 - val_accuracy: 0.3565\n",
      "Epoch 6/300\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 2.0505 - accuracy: 0.2667 - val_loss: 16357.5703 - val_accuracy: 0.3519\n",
      "Epoch 7/300\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 1.9700 - accuracy: 0.3025 - val_loss: 17402.9062 - val_accuracy: 0.3426\n",
      "Epoch 8/300\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 1.9556 - accuracy: 0.3065 - val_loss: 17584.2363 - val_accuracy: 0.4259\n",
      "Epoch 9/300\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 1.8713 - accuracy: 0.3592 - val_loss: 18529.4727 - val_accuracy: 0.3981\n",
      "Epoch 10/300\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 1.8355 - accuracy: 0.3512 - val_loss: 18267.6094 - val_accuracy: 0.4167\n",
      "Epoch 11/300\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 1.7635 - accuracy: 0.3900 - val_loss: 16797.1387 - val_accuracy: 0.4074\n",
      "Epoch 12/300\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 1.7385 - accuracy: 0.3841 - val_loss: 17931.8516 - val_accuracy: 0.4630\n",
      "Epoch 13/300\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 1.6956 - accuracy: 0.3930 - val_loss: 17867.2090 - val_accuracy: 0.4491\n",
      "Epoch 14/300\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 1.6711 - accuracy: 0.4139 - val_loss: 18139.5898 - val_accuracy: 0.4954\n",
      "Epoch 15/300\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 1.6070 - accuracy: 0.4478 - val_loss: 18343.2988 - val_accuracy: 0.4676\n",
      "Epoch 16/300\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 1.5867 - accuracy: 0.4348 - val_loss: 18423.9707 - val_accuracy: 0.4907\n",
      "Epoch 17/300\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 1.5809 - accuracy: 0.4259 - val_loss: 18114.5098 - val_accuracy: 0.5000\n",
      "Epoch 18/300\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 1.5608 - accuracy: 0.4687 - val_loss: 18184.9844 - val_accuracy: 0.4954\n",
      "Epoch 19/300\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 1.5585 - accuracy: 0.4289 - val_loss: 18963.9219 - val_accuracy: 0.4861\n",
      "Epoch 20/300\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 1.4828 - accuracy: 0.4816 - val_loss: 18367.5527 - val_accuracy: 0.5046\n",
      "Epoch 21/300\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 1.4948 - accuracy: 0.4567 - val_loss: 19322.5586 - val_accuracy: 0.4769\n",
      "Epoch 22/300\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 1.4725 - accuracy: 0.4607 - val_loss: 19111.9570 - val_accuracy: 0.4907\n",
      "Epoch 23/300\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 1.4362 - accuracy: 0.5025 - val_loss: 19140.0586 - val_accuracy: 0.5694\n",
      "Epoch 24/300\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 1.3824 - accuracy: 0.5284 - val_loss: 19925.6348 - val_accuracy: 0.5278\n",
      "Epoch 25/300\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 1.3938 - accuracy: 0.5194 - val_loss: 20835.2090 - val_accuracy: 0.5463\n",
      "Epoch 26/300\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 1.4051 - accuracy: 0.5025 - val_loss: 20488.6113 - val_accuracy: 0.5093\n",
      "Epoch 27/300\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 1.3867 - accuracy: 0.5114 - val_loss: 20644.4902 - val_accuracy: 0.5602\n",
      "Epoch 28/300\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 1.3750 - accuracy: 0.5343 - val_loss: 20893.9902 - val_accuracy: 0.5648\n",
      "Epoch 29/300\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 1.3495 - accuracy: 0.5234 - val_loss: 20970.6172 - val_accuracy: 0.5278\n",
      "Epoch 30/300\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 1.3571 - accuracy: 0.5254 - val_loss: 20974.0078 - val_accuracy: 0.5463\n",
      "Epoch 31/300\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 1.3141 - accuracy: 0.5433 - val_loss: 21234.4785 - val_accuracy: 0.5139\n",
      "Epoch 32/300\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 1.2985 - accuracy: 0.5453 - val_loss: 20950.8672 - val_accuracy: 0.5602\n",
      "Epoch 33/300\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 1.2776 - accuracy: 0.5353 - val_loss: 22030.3867 - val_accuracy: 0.5324\n",
      "Epoch 34/300\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 1.2840 - accuracy: 0.5264 - val_loss: 21877.9883 - val_accuracy: 0.5556\n",
      "Epoch 35/300\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 1.2508 - accuracy: 0.5582 - val_loss: 21989.6367 - val_accuracy: 0.5694\n",
      "Epoch 36/300\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 1.2616 - accuracy: 0.5463 - val_loss: 22421.0703 - val_accuracy: 0.5694\n",
      "Epoch 37/300\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 1.2148 - accuracy: 0.5781 - val_loss: 22633.0645 - val_accuracy: 0.5556\n",
      "Epoch 38/300\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 1.2464 - accuracy: 0.5592 - val_loss: 21943.1406 - val_accuracy: 0.5509\n",
      "Epoch 39/300\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 1.2243 - accuracy: 0.5741 - val_loss: 23283.5391 - val_accuracy: 0.5556\n",
      "Epoch 40/300\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 1.2331 - accuracy: 0.5542 - val_loss: 22132.4766 - val_accuracy: 0.5602\n",
      "Epoch 41/300\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 1.2084 - accuracy: 0.5632 - val_loss: 23172.2363 - val_accuracy: 0.5556\n",
      "Epoch 42/300\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 1.1959 - accuracy: 0.5721 - val_loss: 23585.9531 - val_accuracy: 0.5648\n",
      "Epoch 43/300\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 1.2043 - accuracy: 0.5791 - val_loss: 23561.3477 - val_accuracy: 0.5509\n",
      "Epoch 44/300\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 1.2224 - accuracy: 0.5731 - val_loss: 23067.4961 - val_accuracy: 0.5556\n",
      "Epoch 45/300\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 1.1705 - accuracy: 0.5940 - val_loss: 23182.4414 - val_accuracy: 0.5833\n",
      "Epoch 46/300\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 1.1714 - accuracy: 0.5970 - val_loss: 23698.0352 - val_accuracy: 0.5694\n",
      "Epoch 47/300\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 1.1681 - accuracy: 0.6070 - val_loss: 23973.9707 - val_accuracy: 0.5556\n",
      "Epoch 48/300\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 1.1496 - accuracy: 0.5841 - val_loss: 24302.7480 - val_accuracy: 0.5833\n",
      "Epoch 49/300\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 1.1741 - accuracy: 0.5652 - val_loss: 24479.2031 - val_accuracy: 0.5833\n",
      "Epoch 50/300\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 1.1420 - accuracy: 0.5970 - val_loss: 24900.2773 - val_accuracy: 0.5463\n",
      "Epoch 51/300\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 1.1294 - accuracy: 0.6139 - val_loss: 24652.4336 - val_accuracy: 0.5787\n",
      "Epoch 52/300\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 1.1210 - accuracy: 0.5841 - val_loss: 25584.7910 - val_accuracy: 0.5556\n",
      "Epoch 53/300\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 1.1285 - accuracy: 0.5980 - val_loss: 24777.5723 - val_accuracy: 0.5509\n",
      "Epoch 54/300\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 1.0662 - accuracy: 0.6249 - val_loss: 24710.5234 - val_accuracy: 0.5694\n",
      "Epoch 55/300\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 1.1035 - accuracy: 0.6030 - val_loss: 25478.9512 - val_accuracy: 0.5694\n",
      "Epoch 56/300\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 1.1215 - accuracy: 0.6149 - val_loss: 25316.8398 - val_accuracy: 0.5833\n",
      "Epoch 57/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 69ms/step - loss: 1.1027 - accuracy: 0.6000 - val_loss: 26222.0176 - val_accuracy: 0.5694\n",
      "Epoch 58/300\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 1.1011 - accuracy: 0.6060 - val_loss: 24907.6855 - val_accuracy: 0.5787\n",
      "Epoch 59/300\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 1.0568 - accuracy: 0.6398 - val_loss: 25697.3145 - val_accuracy: 0.5787\n",
      "Epoch 60/300\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 1.0885 - accuracy: 0.5801 - val_loss: 25889.1250 - val_accuracy: 0.5278\n",
      "Epoch 61/300\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 1.0672 - accuracy: 0.6080 - val_loss: 25287.9492 - val_accuracy: 0.5880\n",
      "Epoch 62/300\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 1.0437 - accuracy: 0.6209 - val_loss: 25722.9453 - val_accuracy: 0.5648\n",
      "Epoch 63/300\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 1.0686 - accuracy: 0.6179 - val_loss: 25904.4824 - val_accuracy: 0.5741\n",
      "Epoch 64/300\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 1.0506 - accuracy: 0.6189 - val_loss: 26073.6660 - val_accuracy: 0.5602\n",
      "Epoch 65/300\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 1.0721 - accuracy: 0.6020 - val_loss: 26506.6504 - val_accuracy: 0.5741\n",
      "Epoch 66/300\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 1.0693 - accuracy: 0.6030 - val_loss: 27320.5879 - val_accuracy: 0.5787\n",
      "Epoch 67/300\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 1.0334 - accuracy: 0.6328 - val_loss: 26958.4199 - val_accuracy: 0.5694\n",
      "Epoch 68/300\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 1.0618 - accuracy: 0.6299 - val_loss: 27796.4551 - val_accuracy: 0.5602\n",
      "Epoch 69/300\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 1.0536 - accuracy: 0.6209 - val_loss: 26345.4160 - val_accuracy: 0.5787\n",
      "Epoch 70/300\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 1.0142 - accuracy: 0.6269 - val_loss: 27163.2832 - val_accuracy: 0.5648\n",
      "Epoch 71/300\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 1.0317 - accuracy: 0.6189 - val_loss: 27106.4980 - val_accuracy: 0.5833\n",
      "Epoch 72/300\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 1.0313 - accuracy: 0.6448 - val_loss: 26827.3086 - val_accuracy: 0.5648\n",
      "Epoch 73/300\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 1.0417 - accuracy: 0.6219 - val_loss: 28006.3496 - val_accuracy: 0.5509\n",
      "Epoch 74/300\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 1.0131 - accuracy: 0.6418 - val_loss: 27279.0547 - val_accuracy: 0.5741\n",
      "Epoch 75/300\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.9842 - accuracy: 0.6348 - val_loss: 27752.2363 - val_accuracy: 0.5741\n",
      "Epoch 76/300\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.9974 - accuracy: 0.6398 - val_loss: 27705.8301 - val_accuracy: 0.5741\n",
      "Epoch 77/300\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.9833 - accuracy: 0.6627 - val_loss: 28792.1016 - val_accuracy: 0.5694\n",
      "Epoch 78/300\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 1.0108 - accuracy: 0.6279 - val_loss: 28148.1914 - val_accuracy: 0.5648\n",
      "Epoch 79/300\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.9832 - accuracy: 0.6478 - val_loss: 27664.4023 - val_accuracy: 0.5833\n",
      "Epoch 80/300\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.9934 - accuracy: 0.6488 - val_loss: 28303.7949 - val_accuracy: 0.5787\n",
      "Epoch 81/300\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 1.0066 - accuracy: 0.6259 - val_loss: 28435.8496 - val_accuracy: 0.5556\n",
      "Epoch 82/300\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 1.0071 - accuracy: 0.6279 - val_loss: 28986.5039 - val_accuracy: 0.5741\n",
      "Epoch 83/300\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.9685 - accuracy: 0.6617 - val_loss: 29019.3633 - val_accuracy: 0.5787\n",
      "Epoch 84/300\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.9746 - accuracy: 0.6428 - val_loss: 29333.3027 - val_accuracy: 0.5741\n",
      "Epoch 85/300\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 1.0028 - accuracy: 0.6308 - val_loss: 29175.0410 - val_accuracy: 0.5741\n",
      "Epoch 86/300\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.9643 - accuracy: 0.6388 - val_loss: 29464.0020 - val_accuracy: 0.5694\n",
      "Epoch 87/300\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.9505 - accuracy: 0.6627 - val_loss: 30046.0898 - val_accuracy: 0.5509\n",
      "Epoch 88/300\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.9685 - accuracy: 0.6458 - val_loss: 29792.1289 - val_accuracy: 0.5602\n",
      "Epoch 89/300\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.9542 - accuracy: 0.6547 - val_loss: 29134.7832 - val_accuracy: 0.5602\n",
      "Epoch 90/300\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.9449 - accuracy: 0.6547 - val_loss: 29200.5801 - val_accuracy: 0.5880\n",
      "Epoch 91/300\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.9596 - accuracy: 0.6328 - val_loss: 29557.7871 - val_accuracy: 0.5694\n",
      "Epoch 92/300\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.9398 - accuracy: 0.6786 - val_loss: 29662.9746 - val_accuracy: 0.5648\n",
      "Epoch 93/300\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.9403 - accuracy: 0.6428 - val_loss: 29940.1758 - val_accuracy: 0.5694\n",
      "Epoch 94/300\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.9355 - accuracy: 0.6607 - val_loss: 29384.4414 - val_accuracy: 0.5602\n",
      "Epoch 95/300\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.9292 - accuracy: 0.6716 - val_loss: 29047.4199 - val_accuracy: 0.5880\n",
      "Epoch 96/300\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.9496 - accuracy: 0.6567 - val_loss: 30331.5352 - val_accuracy: 0.5741\n",
      "Epoch 97/300\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.9690 - accuracy: 0.6468 - val_loss: 29951.5254 - val_accuracy: 0.5648\n",
      "Epoch 98/300\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.9301 - accuracy: 0.6587 - val_loss: 30432.2031 - val_accuracy: 0.5509\n",
      "Epoch 99/300\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.9454 - accuracy: 0.6408 - val_loss: 30242.2480 - val_accuracy: 0.5602\n",
      "Epoch 100/300\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.9248 - accuracy: 0.6846 - val_loss: 29226.9297 - val_accuracy: 0.5648\n",
      "Epoch 101/300\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.9307 - accuracy: 0.6657 - val_loss: 29688.0996 - val_accuracy: 0.5741\n",
      "Epoch 102/300\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.9216 - accuracy: 0.6677 - val_loss: 29700.0527 - val_accuracy: 0.5694\n",
      "Epoch 103/300\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.8994 - accuracy: 0.6766 - val_loss: 29834.3340 - val_accuracy: 0.5694\n",
      "Epoch 104/300\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.9269 - accuracy: 0.6607 - val_loss: 30818.9883 - val_accuracy: 0.5602\n",
      "Epoch 105/300\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.9274 - accuracy: 0.6567 - val_loss: 30523.8164 - val_accuracy: 0.5926\n",
      "Epoch 106/300\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.9387 - accuracy: 0.6567 - val_loss: 30597.6074 - val_accuracy: 0.5648\n",
      "Epoch 107/300\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.9422 - accuracy: 0.6697 - val_loss: 30981.6621 - val_accuracy: 0.5833\n",
      "Epoch 108/300\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.9388 - accuracy: 0.6677 - val_loss: 30963.1348 - val_accuracy: 0.5833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcd6581e7d0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, epochs=300, validation_data=val_ds, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08a2e3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 44ms/step - loss: 21389.1230 - accuracy: 0.5163\n",
      "Accuracy 0.5162790417671204\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print(\"Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f98ec6b",
   "metadata": {},
   "source": [
    "Optional: Save model for later reuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b58dd68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('models/next_obj_classifier_tablesetting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e33c5a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reloaded_model = tf.keras.models.load_model('models/next_obj_classifier_tablesetting')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b090d1f",
   "metadata": {},
   "source": [
    "### Test model prediction for one sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b50493d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df.loc[0].drop('target').to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "63d9fe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dict = {name: tf.convert_to_tensor([value]) for name, value in sample.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2e68164e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(input_dict)\n",
    "prediction = tf.nn.sigmoid(prediction[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d55466",
   "metadata": {},
   "source": [
    "Get label for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "27161320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'p'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_label = labels[np.argmax(prediction)]\n",
    "pred_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a468d4d7",
   "metadata": {},
   "source": [
    "## 5. Run prediction for each sequence using prequential approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ae9f505d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prequential_error(dataframe, model, labels, nr_of_sequences):\n",
    "    errors = [[] for seq in range(0, nr_of_sequences + 1)]\n",
    "    predictions = [[] for seq in range(0, nr_of_sequences + 1)]\n",
    "    start_token_count = 0\n",
    "    sequence_nr = 0\n",
    "    \n",
    "    for row in trange(dataframe.index[0], dataframe.index[-1]): \n",
    "        observed_target = dataframe.loc[row, 'target']\n",
    "        sample = dataframe.loc[row].drop('target').to_dict()\n",
    "        input_dict = {name: tf.convert_to_tensor([value]) for name, value in \n",
    "                          sample.items()}\n",
    "        predicted_target = model.predict(input_dict)\n",
    "        predicted_target = tf.nn.sigmoid(predicted_target[0])\n",
    "            \n",
    "        pred_label = labels[np.argmax(predicted_target)]\n",
    "        error = 1 - damerauLevenshtein(pred_label, observed_target)\n",
    "        errors[sequence_nr].append(error)\n",
    "        predictions[sequence_nr].append(pred_label)\n",
    "        \n",
    "        if row != 0 and dataframe.loc[row, 'input'] == '<start>':\n",
    "            start_token_count += 1\n",
    "        \n",
    "        if start_token_count > 0:\n",
    "            sequence_nr += 1\n",
    "            start_token_count = 0\n",
    "            \n",
    "    return errors, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c576f3",
   "metadata": {},
   "source": [
    "Define number of sequences (- 1) for which prediction is run. The test run is done on the cleaning up data set, which starts at index 2075."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "02a4e023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nr_of_sequences_preds = len(df[2075:][df[2075:]['input'] == '<start>'])\n",
    "nr_of_sequences_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dbf0e0",
   "metadata": {},
   "source": [
    "Run prediction, sum up errors and get median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d7ae2385",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████| 127/127 [01:24<00:00,  1.50it/s]\n"
     ]
    }
   ],
   "source": [
    "errors, predictions = get_prequential_error(df[2075:], model, labels, nr_of_sequences_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c3eacff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "summed_error = [sum(error) for error in errors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "28e4a79e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(summed_error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.7",
   "language": "python",
   "name": "tf2.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
