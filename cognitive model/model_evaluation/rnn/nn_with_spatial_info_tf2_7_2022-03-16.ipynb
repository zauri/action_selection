{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "8da2a4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from fastDamerauLevenshtein import damerauLevenshtein\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split, GridSearchCV\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49e7518e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/single_step_df_ints_2022-03-15.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99988333",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52fca39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "float_cols = df.select_dtypes(include=['float64']).columns\n",
    "df.loc[:, float_cols] = df.loc[:, float_cols].fillna(-99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8e9acc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "727    l\n",
       "Name: target, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].unique()\n",
    "df['target'].value_counts()\n",
    "\n",
    "df['target'].loc[df['target'] == 'l']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3401a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_of_sequences = len(df[df['input'] == '<start>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "16af1823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove row with target that only occurs once\n",
    "\n",
    "df_new = df.drop(index=727, axis=0)\n",
    "df_new.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5491f1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate stratified split for train - test/val\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=10, test_size=0.3, random_state=42)\n",
    "\n",
    "for train_index, test_index in split.split(df_new, df_new['target']):\n",
    "    strat_train = df_new.loc[train_index]\n",
    "    strat_test_val = df_new.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dc05ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11eba3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split test_val into test and val\n",
    "\n",
    "split_test_val = len(strat_test_val)//2\n",
    "\n",
    "strat_test = strat_test_val[:split_test_val]\n",
    "strat_val = strat_test_val[split_test_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ead4a95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate list of labels to pass to MultiLabelBinarizer so there's the same number of\n",
    "# classes for all datasets\n",
    "\n",
    "labels = df_new['target'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e8da447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataframe, labels, shuffle=True, batch_size=32):\n",
    "    df = dataframe.copy()\n",
    "    labels_ds = df.pop('target')\n",
    "    encoder = MultiLabelBinarizer(classes=labels)\n",
    "    encoded_labels = encoder.fit_transform(labels_ds)\n",
    "    \n",
    "    df = {key: value[:, tf.newaxis] for key, value in df.items()}\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(df), encoded_labels))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=len(dataframe))\n",
    "    \n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(batch_size)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e6e6001",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "416e6d06",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14217/1510453973.py:7: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  df = {key: value[:, tf.newaxis] for key, value in df.items()}\n",
      "2022-03-16 08:25:20.674144: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-16 08:25:20.674611: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-16 08:25:20.674873: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-03-16 08:25:20.675148: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-03-16 08:25:20.675400: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-03-16 08:25:20.675656: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-03-16 08:25:20.675888: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-03-16 08:25:20.676116: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-03-16 08:25:20.676350: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-03-16 08:25:20.676387: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-03-16 08:25:20.678901: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "train_ds = create_dataset(strat_train, labels, batch_size=batch_size)\n",
    "val_ds = create_dataset(strat_val, labels, shuffle=False, batch_size=batch_size)\n",
    "test_ds = create_dataset(strat_test, labels, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ceb42795",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[(train_features, label_batch)] = train_ds.take(1)\n",
    "#print('Every feature:', list(train_features.keys()))\n",
    "#print('A batch of targets:', label_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06f4db47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalization_layer(name, dataset):\n",
    "  # Create a Normalization layer for the feature.\n",
    "    normalizer = layers.Normalization(axis=None)\n",
    "\n",
    "  # Prepare a Dataset that only yields the feature.\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "\n",
    "  # Learn the statistics of the data.\n",
    "    normalizer.adapt(feature_ds)\n",
    "    \n",
    "    return normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "597f7ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_encoding_layer(name, dataset, dtype, max_tokens=None):\n",
    "    if dtype == 'string':\n",
    "        index = layers.StringLookup(max_tokens=max_tokens)\n",
    "    else:\n",
    "        index = layers.IntegerLookup(max_tokens=max_tokens)\n",
    "        \n",
    "    # prepare tf.data.Dataset that only yields the feature    \n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    \n",
    "    # learn set of possible values and assign fixed int index\n",
    "    index.adapt(feature_ds)\n",
    "    \n",
    "    # encode int indices\n",
    "    encoder = layers.CategoryEncoding(num_tokens=index.vocabulary_size())\n",
    "    \n",
    "    # apply multi-hot encoding to indices\n",
    "    # lambda function captures the layer to include them in Keras functional models later\n",
    "    return lambda feature: encoder(index(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ce78468",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_data(dataframe):\n",
    "    all_inputs = []\n",
    "    encoded_features = []\n",
    "    \n",
    "    for header in dataframe.columns:\n",
    "        # numerical features\n",
    "        if 'coord' in header or 'already' in header:\n",
    "            numeric_col = tf.keras.Input(shape=(1,), name=header)\n",
    "            normalization_layer = get_normalization_layer(header, train_ds)\n",
    "            encoded_numeric_col = normalization_layer(numeric_col)\n",
    "            all_inputs.append(numeric_col)\n",
    "            encoded_features.append(encoded_numeric_col)\n",
    "        \n",
    "        # categorical features\n",
    "        elif 'containment' in header or 'food' in header or 'mid' in header or \\\n",
    "        'strong' in header:\n",
    "            categorical_col = tf.keras.Input(shape=(1,), name=header, dtype='int64')\n",
    "            encoding_layer = get_category_encoding_layer(name=header,\n",
    "                                                        dataset=train_ds,\n",
    "                                                        dtype='int64')\n",
    "            encoded_categorical_col = encoding_layer(categorical_col)\n",
    "            all_inputs.append(categorical_col)\n",
    "            encoded_features.append(encoded_categorical_col)\n",
    "            \n",
    "        elif header == 'input':\n",
    "            categorical_col = tf.keras.Input(shape=(1,), name='input', dtype='string')\n",
    "            encoding_layer = get_category_encoding_layer(name='input',\n",
    "                                                        dataset=train_ds,\n",
    "                                                        dtype='string')\n",
    "            encoded_categorical_col = encoding_layer(categorical_col)\n",
    "            all_inputs.append(categorical_col)\n",
    "            encoded_features.append(encoded_categorical_col)\n",
    "            \n",
    "    return all_inputs, encoded_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d333498",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_inputs, encoded_features = create_input_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2de5cf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5caa2ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use model from tutorial with dense layers\n",
    "\n",
    "all_features = tf.keras.layers.concatenate(encoded_features)\n",
    "x = tf.keras.layers.Dense(512, activation=\"relu\")(all_features)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(256, activation=\"relu\")(all_features)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "output = tf.keras.layers.Dense(20)(x)\n",
    "\n",
    "model = tf.keras.Model(all_inputs, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c1736d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5f1f8941",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.keras.utils.plot_model(model, show_shapes=True, rankdir='LR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9dee9ed0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "4/4 [==============================] - 3s 877ms/step - loss: 2.9365 - accuracy: 0.1145 - val_loss: 2.4611 - val_accuracy: 0.2000\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 2.5066 - accuracy: 0.1947 - val_loss: 2.2494 - val_accuracy: 0.2909\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 2.3401 - accuracy: 0.1869 - val_loss: 2.1262 - val_accuracy: 0.3409\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 2.1991 - accuracy: 0.2221 - val_loss: 2.0503 - val_accuracy: 0.3591\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 2.1229 - accuracy: 0.2231 - val_loss: 1.9947 - val_accuracy: 0.3955\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 2.0506 - accuracy: 0.2485 - val_loss: 1.9457 - val_accuracy: 0.4318\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 2.0268 - accuracy: 0.2622 - val_loss: 1.8968 - val_accuracy: 0.4227\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 1.9533 - accuracy: 0.3053 - val_loss: 1.8645 - val_accuracy: 0.4409\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 1.8768 - accuracy: 0.3366 - val_loss: 1.8323 - val_accuracy: 0.4227\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.8155 - accuracy: 0.3493 - val_loss: 1.8013 - val_accuracy: 0.4364\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 1.7913 - accuracy: 0.3679 - val_loss: 1.7656 - val_accuracy: 0.4500\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 1.7516 - accuracy: 0.3914 - val_loss: 1.7380 - val_accuracy: 0.4318\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 1.7318 - accuracy: 0.3865 - val_loss: 1.7109 - val_accuracy: 0.4773\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 1.6743 - accuracy: 0.4110 - val_loss: 1.6825 - val_accuracy: 0.4864\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 1.6609 - accuracy: 0.4129 - val_loss: 1.6530 - val_accuracy: 0.5000\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 1.5917 - accuracy: 0.4560 - val_loss: 1.6175 - val_accuracy: 0.4864\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 1.5860 - accuracy: 0.4648 - val_loss: 1.6007 - val_accuracy: 0.4955\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 1.5666 - accuracy: 0.4530 - val_loss: 1.5949 - val_accuracy: 0.4909\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 1.5225 - accuracy: 0.4706 - val_loss: 1.5672 - val_accuracy: 0.5409\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 1.5406 - accuracy: 0.4765 - val_loss: 1.5478 - val_accuracy: 0.5409\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 1.5051 - accuracy: 0.4716 - val_loss: 1.5293 - val_accuracy: 0.5182\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 1.4480 - accuracy: 0.5088 - val_loss: 1.5120 - val_accuracy: 0.5136\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 1.4246 - accuracy: 0.5049 - val_loss: 1.4956 - val_accuracy: 0.5318\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 1.4020 - accuracy: 0.5166 - val_loss: 1.4772 - val_accuracy: 0.5227\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 1.3835 - accuracy: 0.5225 - val_loss: 1.4638 - val_accuracy: 0.5273\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 1.3824 - accuracy: 0.5196 - val_loss: 1.4436 - val_accuracy: 0.5455\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 1.3329 - accuracy: 0.5597 - val_loss: 1.4320 - val_accuracy: 0.5318\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 1.3450 - accuracy: 0.5421 - val_loss: 1.4204 - val_accuracy: 0.5409\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 1.3177 - accuracy: 0.5323 - val_loss: 1.4130 - val_accuracy: 0.5364\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 1.2908 - accuracy: 0.5724 - val_loss: 1.4030 - val_accuracy: 0.5318\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 1.2606 - accuracy: 0.5841 - val_loss: 1.3928 - val_accuracy: 0.5545\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 1.2616 - accuracy: 0.5695 - val_loss: 1.3767 - val_accuracy: 0.5636\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 1.2579 - accuracy: 0.5812 - val_loss: 1.3745 - val_accuracy: 0.5500\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 1.2473 - accuracy: 0.5724 - val_loss: 1.3673 - val_accuracy: 0.5364\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 1.2430 - accuracy: 0.5509 - val_loss: 1.3576 - val_accuracy: 0.5545\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 1.2337 - accuracy: 0.5714 - val_loss: 1.3419 - val_accuracy: 0.5591\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 1.2022 - accuracy: 0.5890 - val_loss: 1.3360 - val_accuracy: 0.5545\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 1.2110 - accuracy: 0.5930 - val_loss: 1.3379 - val_accuracy: 0.5591\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 1.1963 - accuracy: 0.5910 - val_loss: 1.3325 - val_accuracy: 0.5591\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.1943 - accuracy: 0.6057 - val_loss: 1.3207 - val_accuracy: 0.5545\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 1.1560 - accuracy: 0.6037 - val_loss: 1.3159 - val_accuracy: 0.5591\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 1.1642 - accuracy: 0.6037 - val_loss: 1.3140 - val_accuracy: 0.5455\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 1.1514 - accuracy: 0.6067 - val_loss: 1.3102 - val_accuracy: 0.5500\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.1329 - accuracy: 0.6106 - val_loss: 1.3037 - val_accuracy: 0.5636\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 1.1385 - accuracy: 0.6018 - val_loss: 1.3028 - val_accuracy: 0.5636\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 1.1432 - accuracy: 0.6076 - val_loss: 1.3024 - val_accuracy: 0.5636\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 1.0887 - accuracy: 0.6233 - val_loss: 1.3022 - val_accuracy: 0.5636\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 1.0828 - accuracy: 0.6360 - val_loss: 1.2987 - val_accuracy: 0.5636\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 1.0771 - accuracy: 0.6262 - val_loss: 1.2873 - val_accuracy: 0.5773\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 1.0876 - accuracy: 0.6252 - val_loss: 1.2799 - val_accuracy: 0.5773\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.1116 - accuracy: 0.5988 - val_loss: 1.2826 - val_accuracy: 0.5727\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 1.0819 - accuracy: 0.6067 - val_loss: 1.2838 - val_accuracy: 0.5591\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 1.0847 - accuracy: 0.6164 - val_loss: 1.2846 - val_accuracy: 0.5500\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 1.0766 - accuracy: 0.6282 - val_loss: 1.2891 - val_accuracy: 0.5682\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 1.0565 - accuracy: 0.6399 - val_loss: 1.2945 - val_accuracy: 0.5727\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 1.0142 - accuracy: 0.6566 - val_loss: 1.2910 - val_accuracy: 0.5591\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 1.0542 - accuracy: 0.6517 - val_loss: 1.2816 - val_accuracy: 0.5545\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 1.0493 - accuracy: 0.6243 - val_loss: 1.2711 - val_accuracy: 0.5682\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 43ms/step - loss: 1.0499 - accuracy: 0.6341 - val_loss: 1.2729 - val_accuracy: 0.5727\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 1.0330 - accuracy: 0.6497 - val_loss: 1.2748 - val_accuracy: 0.5682\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 1.0131 - accuracy: 0.6644 - val_loss: 1.2692 - val_accuracy: 0.5727\n",
      "Epoch 62/200\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 1.0028 - accuracy: 0.6419 - val_loss: 1.2642 - val_accuracy: 0.5773\n",
      "Epoch 63/200\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 1.0116 - accuracy: 0.6429 - val_loss: 1.2619 - val_accuracy: 0.5864\n",
      "Epoch 64/200\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 1.0077 - accuracy: 0.6448 - val_loss: 1.2652 - val_accuracy: 0.5773\n",
      "Epoch 65/200\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 1.0178 - accuracy: 0.6389 - val_loss: 1.2677 - val_accuracy: 0.5864\n",
      "Epoch 66/200\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.9871 - accuracy: 0.6526 - val_loss: 1.2727 - val_accuracy: 0.5773\n",
      "Epoch 67/200\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 1.0039 - accuracy: 0.6683 - val_loss: 1.2762 - val_accuracy: 0.5955\n",
      "Epoch 68/200\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.9643 - accuracy: 0.6683 - val_loss: 1.2847 - val_accuracy: 0.5818\n",
      "Epoch 69/200\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.9789 - accuracy: 0.6771 - val_loss: 1.2780 - val_accuracy: 0.5682\n",
      "Epoch 70/200\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.9683 - accuracy: 0.6595 - val_loss: 1.2712 - val_accuracy: 0.5773\n",
      "Epoch 71/200\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.9786 - accuracy: 0.6438 - val_loss: 1.2675 - val_accuracy: 0.5591\n",
      "Epoch 72/200\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.9662 - accuracy: 0.6585 - val_loss: 1.2656 - val_accuracy: 0.5773\n",
      "Epoch 73/200\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.9600 - accuracy: 0.6477 - val_loss: 1.2665 - val_accuracy: 0.5773\n",
      "Epoch 74/200\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.9456 - accuracy: 0.6605 - val_loss: 1.2642 - val_accuracy: 0.5773\n",
      "Epoch 75/200\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.9208 - accuracy: 0.6742 - val_loss: 1.2585 - val_accuracy: 0.5727\n",
      "Epoch 76/200\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.9792 - accuracy: 0.6517 - val_loss: 1.2657 - val_accuracy: 0.5682\n",
      "Epoch 77/200\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.9446 - accuracy: 0.6634 - val_loss: 1.2743 - val_accuracy: 0.5864\n",
      "Epoch 78/200\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.9382 - accuracy: 0.6800 - val_loss: 1.2783 - val_accuracy: 0.5636\n",
      "Epoch 79/200\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.9549 - accuracy: 0.6595 - val_loss: 1.2705 - val_accuracy: 0.5727\n",
      "Epoch 80/200\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.9241 - accuracy: 0.6781 - val_loss: 1.2739 - val_accuracy: 0.5727\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds, epochs=200, validation_data=val_ds, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b5ec9bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6780821681022644"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history['accuracy'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "08a2e3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 95ms/step - loss: 1.4104 - accuracy: 0.5251\n",
      "Accuracy 0.5251141786575317\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print(\"Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "de4c67a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_accuracy(train_ds, test_ds, val_ds, \n",
    "                       all_inputs=all_inputs, encoded_features=encoded_features,\n",
    "                       callback=callback):\n",
    "    accuracy_list = []\n",
    "    \n",
    "    dropout_rate = [0.2,0.3,0.4,0.5,0.6,0.7]\n",
    "    neurons = [128,256,512,1024]\n",
    "    \n",
    "    for dropout in dropout_rate:\n",
    "        for neuron_nr in neurons:\n",
    "            all_features = tf.keras.layers.concatenate(encoded_features)\n",
    "            x = tf.keras.layers.Dense(neuron_nr, activation='relu')(all_features)\n",
    "            x = tf.keras.layers.Dropout(dropout)(x)\n",
    "            x = tf.keras.layers.Dense(neuron_nr//2, activation='relu')(all_features)\n",
    "            x = tf.keras.layers.Dropout(dropout)(x)\n",
    "            output = tf.keras.layers.Dense(20)(x)\n",
    "    \n",
    "            model = tf.keras.Model(all_inputs, output)\n",
    "    \n",
    "            model.compile(optimizer='adam',\n",
    "                 loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                 metrics=['accuracy'])\n",
    "    \n",
    "            history = model.fit(train_ds, epochs=200, validation_data=val_ds, \n",
    "                                callbacks=[callback], verbose=0)\n",
    "            accuracy = history.history['accuracy'][-1]\n",
    "    \n",
    "            loss, accuracy_test = model.evaluate(test_ds)\n",
    "    \n",
    "            accuracy_list.append([accuracy, accuracy_test, 'params (neurons, dropout): ', neuron_nr, dropout])\n",
    "    \n",
    "    return accuracy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5bf18b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test = create_model(128, 0.5, all_inputs, encoded_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4a8428",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_test.fit(train_ds, epochs=200, validation_data=val_ds, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b2486a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 94ms/step - loss: 1.3957 - accuracy: 0.5205\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 1.3771 - accuracy: 0.5205\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 1.4059 - accuracy: 0.5388\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 1.4685 - accuracy: 0.5160\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 1.4125 - accuracy: 0.5525\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 1.4262 - accuracy: 0.5114\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 1.4272 - accuracy: 0.5160\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 1.4903 - accuracy: 0.5160\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 1.4829 - accuracy: 0.5297\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 1.4314 - accuracy: 0.5160\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.4201 - accuracy: 0.5571\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 1.4746 - accuracy: 0.5297\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.4765 - accuracy: 0.5205\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 1.3922 - accuracy: 0.5251\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 1.4140 - accuracy: 0.5297\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.4232 - accuracy: 0.5251\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.8104 - accuracy: 0.4064\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.4488 - accuracy: 0.5479\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.4262 - accuracy: 0.5297\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.4400 - accuracy: 0.5571\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 1.6699 - accuracy: 0.4886\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 1.4905 - accuracy: 0.5434\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 1.4332 - accuracy: 0.5342\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.4966 - accuracy: 0.5251\n"
     ]
    }
   ],
   "source": [
    "accuracies = get_model_accuracy(train_ds, test_ds, val_ds, all_inputs, encoded_features, callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "6c50d210",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['accuracy', 'test_accuracy', 'neurons', 'dropout'])\n",
    "results['accuracy'] = [lst[0] for lst in accuracies]\n",
    "results['test_accuracy'] = [lst[1] for lst in accuracies]\n",
    "results['neurons'] = [lst[3] for lst in accuracies]\n",
    "results['dropout'] = [lst[4] for lst in accuracies]\n",
    "results['diff'] = abs(results['accuracy'] - results['test_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "3a4a2db1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy           0.533268\n",
       "test_accuracy      0.520548\n",
       "neurons          128.000000\n",
       "dropout            0.500000\n",
       "diff               0.012720\n",
       "Name: 12, dtype: float64"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highest_acc = results['accuracy'].idxmax()\n",
    "lowest_diff = results['diff'].idxmin()\n",
    "\n",
    "results.loc[highest_acc, :]\n",
    "results.loc[lowest_diff, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "b45a39ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>neurons</th>\n",
       "      <th>dropout</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.650685</td>\n",
       "      <td>0.520548</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.130137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.686888</td>\n",
       "      <td>0.520548</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.166341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.740704</td>\n",
       "      <td>0.538813</td>\n",
       "      <td>512</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.201892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.746575</td>\n",
       "      <td>0.515982</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.230594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.636986</td>\n",
       "      <td>0.552511</td>\n",
       "      <td>128</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.084475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.621331</td>\n",
       "      <td>0.511416</td>\n",
       "      <td>256</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.109915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.739726</td>\n",
       "      <td>0.515982</td>\n",
       "      <td>512</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.223744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.755382</td>\n",
       "      <td>0.515982</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.239400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.562622</td>\n",
       "      <td>0.529680</td>\n",
       "      <td>128</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.032942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.619374</td>\n",
       "      <td>0.515982</td>\n",
       "      <td>256</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.103392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.702544</td>\n",
       "      <td>0.557078</td>\n",
       "      <td>512</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.145466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.742661</td>\n",
       "      <td>0.529680</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.212981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.533268</td>\n",
       "      <td>0.520548</td>\n",
       "      <td>128</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.012720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.617417</td>\n",
       "      <td>0.525114</td>\n",
       "      <td>256</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.092303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.650685</td>\n",
       "      <td>0.529680</td>\n",
       "      <td>512</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.121005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.701566</td>\n",
       "      <td>0.525114</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.176451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.360078</td>\n",
       "      <td>0.406393</td>\n",
       "      <td>128</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.046314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.610568</td>\n",
       "      <td>0.547945</td>\n",
       "      <td>256</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.062622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.647749</td>\n",
       "      <td>0.529680</td>\n",
       "      <td>512</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.118069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.683953</td>\n",
       "      <td>0.557078</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.126875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.378669</td>\n",
       "      <td>0.488584</td>\n",
       "      <td>128</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.109915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.522505</td>\n",
       "      <td>0.543379</td>\n",
       "      <td>256</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.020874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.593933</td>\n",
       "      <td>0.534247</td>\n",
       "      <td>512</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.059687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.653620</td>\n",
       "      <td>0.525114</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.128506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy  test_accuracy  neurons  dropout      diff\n",
       "0   0.650685       0.520548      128      0.2  0.130137\n",
       "1   0.686888       0.520548      256      0.2  0.166341\n",
       "2   0.740704       0.538813      512      0.2  0.201892\n",
       "3   0.746575       0.515982     1024      0.2  0.230594\n",
       "4   0.636986       0.552511      128      0.3  0.084475\n",
       "5   0.621331       0.511416      256      0.3  0.109915\n",
       "6   0.739726       0.515982      512      0.3  0.223744\n",
       "7   0.755382       0.515982     1024      0.3  0.239400\n",
       "8   0.562622       0.529680      128      0.4  0.032942\n",
       "9   0.619374       0.515982      256      0.4  0.103392\n",
       "10  0.702544       0.557078      512      0.4  0.145466\n",
       "11  0.742661       0.529680     1024      0.4  0.212981\n",
       "12  0.533268       0.520548      128      0.5  0.012720\n",
       "13  0.617417       0.525114      256      0.5  0.092303\n",
       "14  0.650685       0.529680      512      0.5  0.121005\n",
       "15  0.701566       0.525114     1024      0.5  0.176451\n",
       "16  0.360078       0.406393      128      0.6  0.046314\n",
       "17  0.610568       0.547945      256      0.6  0.062622\n",
       "18  0.647749       0.529680      512      0.6  0.118069\n",
       "19  0.683953       0.557078     1024      0.6  0.126875\n",
       "20  0.378669       0.488584      128      0.7  0.109915\n",
       "21  0.522505       0.543379      256      0.7  0.020874\n",
       "22  0.593933       0.534247      512      0.7  0.059687\n",
       "23  0.653620       0.525114     1024      0.7  0.128506"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "2be1a85c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fbc051e6400>"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "x = [x for x in range(0, len(results))]\n",
    "median_acc = [np.median(results['accuracy'])] * len(x)\n",
    "median_test_acc = [np.median(results['test_accuracy'])] * len(x)\n",
    "std = [results['accuracy'].std()] * len(x)\n",
    "std_test = [results['test_accuracy'].std()] * len(x)\n",
    "labels = ['train acc', 'test acc']\n",
    "\n",
    "fig, (ax0, ax1) = plt.subplots(nrows=1, ncols=2, sharex=False, sharey=False, figsize=(12,6))\n",
    "\n",
    "ax0.boxplot([results['accuracy'], results['test_accuracy']], patch_artist=True,\n",
    "            labels=labels, showmeans=True,\n",
    "            boxprops=dict(facecolor='aliceblue', color='black'),\n",
    "            meanprops=dict(marker='D', markerfacecolor='darkred', markeredgecolor='black'),\n",
    "            medianprops=dict(linestyle='-', color='darkgreen', linewidth=1.5),\n",
    "            flierprops=dict(marker='o', markeredgecolor='firebrick', markersize=8,\n",
    "                           markerfacecolor='orangered'))\n",
    "\n",
    "#ax0.legend(fontsize=10, framealpha=0.8, loc='upper right')\n",
    "\n",
    "#ax0 = sns.boxplot(data=results.iloc[:,:2])\n",
    "\n",
    "ax1.scatter(x, results['accuracy'], s=18, c='navy')\n",
    "ax1.plot(x, median_acc, c='dodgerblue', label='accuracy median')\n",
    "ax1.fill_between(x, median_acc, results['accuracy'], \n",
    "                 alpha=0.2, color='dodgerblue')\n",
    "\n",
    "ax1.scatter(x, results['test_accuracy'], s=18, c='limegreen')\n",
    "ax1.plot(x, median_test_acc, c='green', label='test accuracy median')\n",
    "ax1.fill_between(x, median_test_acc, results['test_accuracy'], \n",
    "                 alpha=0.2, color='limegreen')\n",
    "\n",
    "plt.ylim(0.3, 0.8)\n",
    "ax1.legend(fontsize=10, framealpha=0.8, loc='upper right', markerscale=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b0c677",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b58dd68b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-15 14:05:03.524192: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Function `_wrapped_model` contains input name(s) start_coords.x, start_coords.y, start_coords.z, l.already_seen, d.already_seen, g.already_seen, f.already_seen, r.already_seen, z.already_seen, c.already_seen, w.already_seen, k.already_seen, p.already_seen, q.already_seen, t.already_seen, h.already_seen, x.already_seen, s.already_seen, e.already_seen, m.already_seen, b.already_seen, n.already_seen, o.already_seen, a.already_seen, coordinates_p.x, coordinates_p.y, coordinates_p.z, p.containment, p.food_k, p.strong_k, p.mid_k, coordinates_o.x, coordinates_o.y, coordinates_o.z, o.containment, o.food_k, o.strong_k, o.mid_k, coordinates_c.x, coordinates_c.y, coordinates_c.z, c.containment, c.food_k, c.strong_k, c.mid_k, coordinates_g.x, coordinates_g.y, coordinates_g.z, g.containment, g.food_k, g.strong_k, g.mid_k, coordinates_k.x, coordinates_k.y, coordinates_k.z, k.containment, k.food_k, k.strong_k, k.mid_k, coordinates_r.x, coordinates_r.y, coordinates_r.z, r.containment, r.food_k, r.strong_k, r.mid_k, coordinates_w.x, coordinates_w.y, coordinates_w.z, w.containment, w.food_k, w.strong_k, w.mid_k, coordinates_f.x, coordinates_f.y, coordinates_f.z, f.containment, f.food_k, f.strong_k, f.mid_k, coordinates_s.x, coordinates_s.y, coordinates_s.z, s.containment, s.food_k, s.strong_k, s.mid_k, coordinates_t.x, coordinates_t.y, coordinates_t.z, t.containment, t.food_k, t.strong_k, t.mid_k, coordinates_e.x, coordinates_e.y, coordinates_e.z, e.containment, e.food_k, e.strong_k, e.mid_k, coordinates_n.x, coordinates_n.y, coordinates_n.z, n.containment, n.food_k, n.strong_k, n.mid_k, coordinates_z.x, coordinates_z.y, coordinates_z.z, z.containment, z.food_k, z.strong_k, z.mid_k, coordinates_m.x, coordinates_m.y, coordinates_m.z, m.containment, m.food_k, m.strong_k, m.mid_k, coordinates_x.x, coordinates_x.y, coordinates_x.z, x.containment, x.food_k, x.strong_k, x.mid_k, coordinates_b.x, coordinates_b.y, coordinates_b.z, b.containment, b.food_k, b.strong_k, b.mid_k, coordinates_d.x, coordinates_d.y, coordinates_d.z, d.containment, d.food_k, d.strong_k, d.mid_k, coordinates_l.x, coordinates_l.y, coordinates_l.z, l.containment, l.food_k, l.strong_k, l.mid_k, coordinates_a.x, coordinates_a.y, coordinates_a.z, a.containment, a.food_k, a.strong_k, a.mid_k, coordinates_h.x, coordinates_h.y, coordinates_h.z, h.containment, h.food_k, h.strong_k, h.mid_k, coordinates_q.x, coordinates_q.y, coordinates_q.z, q.containment, q.food_k, q.strong_k, q.mid_k with unsupported characters which will be renamed to start_coords_x, start_coords_y, start_coords_z, l_already_seen, d_already_seen, g_already_seen, f_already_seen, r_already_seen, z_already_seen, c_already_seen, w_already_seen, k_already_seen, p_already_seen, q_already_seen, t_already_seen, h_already_seen, x_already_seen, s_already_seen, e_already_seen, m_already_seen, b_already_seen, n_already_seen, o_already_seen, a_already_seen, coordinates_p_x, coordinates_p_y, coordinates_p_z, p_containment, p_food_k, p_strong_k, p_mid_k, coordinates_o_x, coordinates_o_y, coordinates_o_z, o_containment, o_food_k, o_strong_k, o_mid_k, coordinates_c_x, coordinates_c_y, coordinates_c_z, c_containment, c_food_k, c_strong_k, c_mid_k, coordinates_g_x, coordinates_g_y, coordinates_g_z, g_containment, g_food_k, g_strong_k, g_mid_k, coordinates_k_x, coordinates_k_y, coordinates_k_z, k_containment, k_food_k, k_strong_k, k_mid_k, coordinates_r_x, coordinates_r_y, coordinates_r_z, r_containment, r_food_k, r_strong_k, r_mid_k, coordinates_w_x, coordinates_w_y, coordinates_w_z, w_containment, w_food_k, w_strong_k, w_mid_k, coordinates_f_x, coordinates_f_y, coordinates_f_z, f_containment, f_food_k, f_strong_k, f_mid_k, coordinates_s_x, coordinates_s_y, coordinates_s_z, s_containment, s_food_k, s_strong_k, s_mid_k, coordinates_t_x, coordinates_t_y, coordinates_t_z, t_containment, t_food_k, t_strong_k, t_mid_k, coordinates_e_x, coordinates_e_y, coordinates_e_z, e_containment, e_food_k, e_strong_k, e_mid_k, coordinates_n_x, coordinates_n_y, coordinates_n_z, n_containment, n_food_k, n_strong_k, n_mid_k, coordinates_z_x, coordinates_z_y, coordinates_z_z, z_containment, z_food_k, z_strong_k, z_mid_k, coordinates_m_x, coordinates_m_y, coordinates_m_z, m_containment, m_food_k, m_strong_k, m_mid_k, coordinates_x_x, coordinates_x_y, coordinates_x_z, x_containment, x_food_k, x_strong_k, x_mid_k, coordinates_b_x, coordinates_b_y, coordinates_b_z, b_containment, b_food_k, b_strong_k, b_mid_k, coordinates_d_x, coordinates_d_y, coordinates_d_z, d_containment, d_food_k, d_strong_k, d_mid_k, coordinates_l_x, coordinates_l_y, coordinates_l_z, l_containment, l_food_k, l_strong_k, l_mid_k, coordinates_a_x, coordinates_a_y, coordinates_a_z, a_containment, a_food_k, a_strong_k, a_mid_k, coordinates_h_x, coordinates_h_y, coordinates_h_z, h_containment, h_food_k, h_strong_k, h_mid_k, coordinates_q_x, coordinates_q_y, coordinates_q_z, q_containment, q_food_k, q_strong_k, q_mid_k in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/next_obj_classifier_2022-03-15/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/next_obj_classifier_2022-03-15/assets\n"
     ]
    }
   ],
   "source": [
    "#model.save('models/next_obj_classifier_2022-03-15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e33c5a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reloaded_model = tf.keras.models.load_model('next_obj_classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29a6bfd0",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nsample = df.loc[0].drop('target').to_dict()\\ninput_dict = {name: tf.convert_to_tensor([value]) for name, value in sample.items()}\\nprediction = reloaded_model.predict(input_dict)\\nprediction = tf.nn.sigmoid(prediction[0])\\n\\n# get label for prediction\\n\\npred_label = labels[np.argmax(prediction)]\\npred_label\\n\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test prediction for one sample\n",
    "\n",
    "'''\n",
    "sample = df.loc[0].drop('target').to_dict()\n",
    "input_dict = {name: tf.convert_to_tensor([value]) for name, value in sample.items()}\n",
    "prediction = reloaded_model.predict(input_dict)\n",
    "prediction = tf.nn.sigmoid(prediction[0])\n",
    "\n",
    "# get label for prediction\n",
    "\n",
    "pred_label = labels[np.argmax(prediction)]\n",
    "pred_label\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ae9f505d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prequential_error(dataframe, model, labels, nr_of_sequences):\n",
    "    errors = [[] for seq in range(0, nr_of_sequences + 1)]\n",
    "    start_token_count = 0\n",
    "    sequence_nr = 0\n",
    "    \n",
    "    for row in range(0, len(dataframe)): \n",
    "        observed_target = dataframe.loc[row, 'target']\n",
    "        sample = dataframe.loc[row].drop('target').to_dict()\n",
    "        input_dict = {name: tf.convert_to_tensor([value]) for name, value in \n",
    "                          sample.items()}\n",
    "        predicted_target = model.predict(input_dict)\n",
    "        predicted_target = tf.nn.sigmoid(predicted_target[0])\n",
    "            \n",
    "        pred_label = labels[np.argmax(predicted_target)]\n",
    "        error = 1 - damerauLevenshtein(pred_label, observed_target)\n",
    "        errors[sequence_nr].append(error)\n",
    "        \n",
    "        if row != 0 and dataframe.loc[row, 'input'] == '<start>':\n",
    "            start_token_count += 1\n",
    "        \n",
    "        if start_token_count > 0:\n",
    "            sequence_nr += 1\n",
    "            start_token_count = 0\n",
    "            \n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d7ae2385",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = get_prequential_error(df, model, labels, nr_of_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c3eacff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "summed_error = [sum(error) for error in errors[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "28e4a79e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(summed_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9edef143",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('results/nn_spatialinfo_prequential_summed_2022-03-15.txt', 'w') as file:\n",
    "#    file.write(str(summed_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cf9a2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.7",
   "language": "python",
   "name": "tf2.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
