{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fastDamerauLevenshtein import damerauLevenshtein\n",
    "import ast\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prediction():\n",
    "    Item = None\n",
    "    Parent = None\n",
    "    Children = None\n",
    "\n",
    "    def __init__(self, itemValue=None):\n",
    "        self.Item = itemValue\n",
    "        self.Children = []\n",
    "        self.Parent = None\n",
    "\n",
    "    def get_child(self, target):\n",
    "        for chld in self.Children:\n",
    "            if chld.Item == target:\n",
    "                return chld\n",
    "        return None\n",
    "\n",
    "    def get_children(self):\n",
    "        return self.Children\n",
    "\n",
    "    def has_child(self, target):\n",
    "        found = self.get_child(target)\n",
    "        if found is not None:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def add_new_child(self, child):\n",
    "        newchild = Prediction(child)\n",
    "        newchild.Parent = self\n",
    "        self.Children.append(newchild)\n",
    "\n",
    "    def remove_child(self, child):\n",
    "        for chld in self.Children:\n",
    "            if chld.Item == child:\n",
    "                self.Children.remove(chld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CPT():\n",
    "    alphabet = None\n",
    "    root = None\n",
    "    inverted_index = None\n",
    "    lookup_table = None\n",
    "    def __init__(self):\n",
    "        self.alphabet = set()\n",
    "        self.root = Prediction()\n",
    "        self.inverted_index = {}\n",
    "        self.lookup_table = {}\n",
    "\n",
    "    def load_files(self, train_file, test_file=None):\n",
    "        \"\"\"\n",
    "        This function reads in the wide csv file of sequences separated by commas and returns a list of list of \n",
    "        those sequences. The sequences are defined as below.\n",
    "        seq1 = A,B,C,D\n",
    "        seq2 = B,C,E\n",
    "        Returns: [[A,B,C,D],[B,C,E]]\n",
    "        \"\"\"\n",
    "        \n",
    "        train = []\n",
    "        test = []\n",
    "\n",
    "        if train_file is None:\n",
    "            return train_file\n",
    "\n",
    "        train_data = pd.read_csv(train_file, header=0)\n",
    "\n",
    "        for index, row in train_data.iterrows():\n",
    "            train.append(row.values)\n",
    "\n",
    "        if test_file is not None:\n",
    "\n",
    "            test_data = pd.read_csv(test_file, header=None)\n",
    "\n",
    "            for index, row in test_data.iterrows():\n",
    "                train.append(row.values)\n",
    "                test.append(list(row.values))\n",
    "\n",
    "            return train, test\n",
    "\n",
    "        return train\n",
    "\n",
    "\n",
    "    def train(self, data):\n",
    "        \"\"\"\n",
    "         This functions populates the Prediction Tree, Inverted Index and LookUp Table for the algorithm.\n",
    "         Input: The list of list training data\n",
    "         Output : Boolean True\n",
    "         \"\"\"\n",
    "\n",
    "        cursornode = self.root\n",
    "\n",
    "        for seqid, row in enumerate(data):\n",
    "            for element in row:\n",
    "                if element == element: # different sequence length support\n",
    "                    \n",
    "                    if cursornode.has_child(element) == False:\n",
    "                        cursornode.add_new_child(element)\n",
    "                        cursornode = cursornode.get_child(element)\n",
    "                    else:\n",
    "                        cursornode = cursornode.get_child(element)\n",
    "\n",
    "                # adding to the inverted index\n",
    "\n",
    "                    if self.inverted_index.get(element) is None:\n",
    "                        self.inverted_index[element] = set()\n",
    "\n",
    "                    self.inverted_index[element].add(seqid)\n",
    "\n",
    "                    self.alphabet.add(element)\n",
    "\n",
    "            self.lookup_table[seqid] = cursornode\n",
    "\n",
    "            cursornode = self.root\n",
    "\n",
    "        return True\n",
    "\n",
    "    def score(self, counttable, key, length, target_size, number_of_similar_sequences, number_items_counttable):\n",
    "        \"\"\"\n",
    "         This functions populates the Prediction Tree, Inverted Index and LookUp Table for the algorithm.\n",
    "         Input: The list of list training data\n",
    "         Output : count table\n",
    "         \"\"\"\n",
    "        \n",
    "        weight_level = 1 / number_of_similar_sequences\n",
    "        weight_distance = 1 / number_items_counttable\n",
    "        score = 1 + weight_level + weight_distance * 0.001\n",
    "\n",
    "        if counttable.get(key) is None:\n",
    "            counttable[key] = score\n",
    "        else:\n",
    "            counttable[key] = score * counttable.get(key)\n",
    "\n",
    "        return counttable\n",
    "\n",
    "    def predict(self, data, target, k, n):\n",
    "        \"\"\"\n",
    "        Here target is the test dataset in the form of list of list,\n",
    "        k is the number of last elements that will be used to find similar sequences and,\n",
    "        n is the number of predictions required.\n",
    "        Input: training list of list, target list of list, k,n\n",
    "        Output: max n predictions for each sequence\n",
    "        \"\"\"\n",
    "\n",
    "        predictions = []\n",
    "\n",
    "        for index, each_target in enumerate(target):\n",
    "            #print(each_target)\n",
    "            each_target = list(each_target)\n",
    "            #n = int(n_list[index])\n",
    "            \n",
    "            # different sequence length support\n",
    "            i = 0\n",
    "            while i < len(each_target) and each_target[i] == each_target[i]:  # find NaN start\n",
    "                i = i + 1\n",
    "            l = i - k - 1\n",
    "            if l < 0:\n",
    "                l = 0\n",
    "            \n",
    "            each_target = each_target[l:i]\n",
    "\n",
    "            intersection = set(range(0, len(data)))\n",
    "\n",
    "            for element in each_target:\n",
    "                if self.inverted_index.get(element) is None:\n",
    "                    continue\n",
    "                intersection = intersection & self.inverted_index.get(element)\n",
    "\n",
    "            similar_sequences = []\n",
    "\n",
    "            for element in intersection:\n",
    "                currentnode = self.lookup_table.get(element)\n",
    "                tmp = []\n",
    "                while currentnode.Item is not None:\n",
    "                    tmp.append(currentnode.Item)\n",
    "                    currentnode = currentnode.Parent\n",
    "                similar_sequences.append(tmp)\n",
    "\n",
    "            for sequence in similar_sequences:\n",
    "                sequence.reverse()\n",
    "\n",
    "            counttable = {}\n",
    "\n",
    "            for sequence in similar_sequences:\n",
    "                try:\n",
    "                    index = next(\n",
    "                        i for i, v in zip(range(len(sequence) - 1, 0, -1), reversed(sequence)) if v == each_target[-1])\n",
    "                except:\n",
    "                    index = None\n",
    "                if index is not None:\n",
    "                    count = 1\n",
    "                    for element in sequence[index + 1:]:\n",
    "                        if element in each_target:\n",
    "                            continue\n",
    "\n",
    "                        counttable = self.score(counttable, element, len(each_target), len(each_target),\n",
    "                                                len(similar_sequences), count)\n",
    "                        #print(counttable)\n",
    "                        count += 1\n",
    "\n",
    "            pred = self.get_n_largest(counttable, n)\n",
    "            predictions.append(pred)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    def get_n_largest(self, dictionary, n):\n",
    "\n",
    "        largest = sorted(dictionary.items(), key=lambda t: t[1], reverse=True)[:n]\n",
    "        return [key for key, _ in largest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CPT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = model.load_files('data/all_data_train_firstelem.csv', 'data/all_data_test_7_firstelem.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get length of each sequence (ignoring nan) minus given sequence in test\n",
    "n_list = [np.count_nonzero(~pd.isnull(x)) - 1 for x in train]\n",
    "n_list = [x if x > 0 else 0 for x in n_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_string(string):\n",
    "    output = ''\n",
    "    for lst in string:\n",
    "        for elem in lst:\n",
    "            output += elem\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary evaluation of errors in each step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = [[] for x in range(0,len(train)//2)]\n",
    "\n",
    "for seq in range(0,len(train)//2):\n",
    "    i = 1\n",
    "    while i <= n_list[seq]:\n",
    "        next_char = model.predict(train, test[seq][i-1:i], 3, 1)\n",
    "        next_char = get_string(next_char)\n",
    "        predicted = next_char\n",
    "        observed = train[seq][i]\n",
    "        #print('pred: ', predicted, 'obs: ', observed, i)\n",
    "        error = 1 - damerauLevenshtein(predicted, observed)\n",
    "        \n",
    "        errors[seq].append(error)\n",
    "        i += 1\n",
    "    #print('----------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summed_error = [sum(error[1:]) for error in errors]\n",
    "np.median(summed_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/cpt_prequential_summed_startfromzero.txt', 'w') as f:\n",
    "    f.write(str(summed_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
