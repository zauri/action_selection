{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8da2a4b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from fastDamerauLevenshtein import damerauLevenshtein\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
    "from tensorflow.keras import layers\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36834bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "49e7518e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14932/4015456590.py:1: DtypeWarning: Columns (59,60,61,62,66,67,68,69,73,74,75,76,87,88,89,90,94,95,96,97,101,102,103,104,108,109,110,111,115,116,117,118,122,123,124,125,129,130,131,132,136,137,138,139,143,144,145,146,150,151,152,153,164,165,166,167,178,179,180,181,185,186,187,188,192,193,194,195,199,200,201,202,213,214,215,216,220,221,222,223,227,228,229,230,234,235,236,237,241,242,243,244,248,249,250,251,255,256,257,258,262,263,264,265,269,270,271,272,276,277,278,279,283,284,285,286,290,291,292,293,297,298,299,300,304,305,306,307,311,312,313,314,318,319,320,321,325,326,327,328,332,333,334,335,339,340,341,342,346,347,348,349,353,354,355,356) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('data/single_step_df_ints_2022-09-12_encoded.csv', header=0)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/single_step_df_ints_2022-09-12_encoded.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "99988333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "      <th>start_coords.x</th>\n",
       "      <th>start_coords.y</th>\n",
       "      <th>start_coords.z</th>\n",
       "      <th>R.already_seen</th>\n",
       "      <th>x.already_seen</th>\n",
       "      <th>s.already_seen</th>\n",
       "      <th>silverware_1.already_seen</th>\n",
       "      <th>V.already_seen</th>\n",
       "      <th>...</th>\n",
       "      <th>F.food_k</th>\n",
       "      <th>F.strong_k</th>\n",
       "      <th>F.mid_k</th>\n",
       "      <th>coordinates_X.x</th>\n",
       "      <th>coordinates_X.y</th>\n",
       "      <th>coordinates_X.z</th>\n",
       "      <th>X.containment</th>\n",
       "      <th>X.food_k</th>\n",
       "      <th>X.strong_k</th>\n",
       "      <th>X.mid_k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;start&gt;</td>\n",
       "      <td>p</td>\n",
       "      <td>-0.451354</td>\n",
       "      <td>-0.413918</td>\n",
       "      <td>0.156247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p</td>\n",
       "      <td>o</td>\n",
       "      <td>0.513000</td>\n",
       "      <td>-0.531000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>o</td>\n",
       "      <td>c</td>\n",
       "      <td>0.513000</td>\n",
       "      <td>-0.531000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c</td>\n",
       "      <td>g</td>\n",
       "      <td>0.513000</td>\n",
       "      <td>-0.531000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>g</td>\n",
       "      <td>k</td>\n",
       "      <td>0.513000</td>\n",
       "      <td>-0.531000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>O</td>\n",
       "      <td>R</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2199</th>\n",
       "      <td>R</td>\n",
       "      <td>S</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2200</th>\n",
       "      <td>S</td>\n",
       "      <td>T</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2201</th>\n",
       "      <td>T</td>\n",
       "      <td>U</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2202</th>\n",
       "      <td>U</td>\n",
       "      <td>V</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2203 rows Ã— 357 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        input target  start_coords.x  start_coords.y  start_coords.z  \\\n",
       "0     <start>      p       -0.451354       -0.413918        0.156247   \n",
       "1           p      o        0.513000       -0.531000        0.740000   \n",
       "2           o      c        0.513000       -0.531000        0.740000   \n",
       "3           c      g        0.513000       -0.531000        0.740000   \n",
       "4           g      k        0.513000       -0.531000        0.740000   \n",
       "...       ...    ...             ...             ...             ...   \n",
       "2198        O      R        2.500000        4.500000        2.000000   \n",
       "2199        R      S        2.500000        4.500000        2.000000   \n",
       "2200        S      T        2.500000        4.500000        2.000000   \n",
       "2201        T      U        2.500000        4.500000        2.000000   \n",
       "2202        U      V        2.500000        4.500000        2.000000   \n",
       "\n",
       "      R.already_seen  x.already_seen  s.already_seen  \\\n",
       "0                0.0             0.0             0.0   \n",
       "1                0.0             0.0             0.0   \n",
       "2                0.0             0.0             0.0   \n",
       "3                0.0             0.0             0.0   \n",
       "4                0.0             0.0             0.0   \n",
       "...              ...             ...             ...   \n",
       "2198             0.0             0.0             0.0   \n",
       "2199             1.0             0.0             0.0   \n",
       "2200             1.0             0.0             0.0   \n",
       "2201             1.0             0.0             0.0   \n",
       "2202             1.0             0.0             0.0   \n",
       "\n",
       "      silverware_1.already_seen  V.already_seen  ...  F.food_k  F.strong_k  \\\n",
       "0                           0.0             0.0  ...       NaN         NaN   \n",
       "1                           0.0             0.0  ...       NaN         NaN   \n",
       "2                           0.0             0.0  ...       NaN         NaN   \n",
       "3                           0.0             0.0  ...       NaN         NaN   \n",
       "4                           0.0             0.0  ...       NaN         NaN   \n",
       "...                         ...             ...  ...       ...         ...   \n",
       "2198                        1.0             0.0  ...       NaN         NaN   \n",
       "2199                        1.0             0.0  ...       NaN         NaN   \n",
       "2200                        1.0             0.0  ...       NaN         NaN   \n",
       "2201                        1.0             0.0  ...       NaN         NaN   \n",
       "2202                        1.0             0.0  ...       NaN         NaN   \n",
       "\n",
       "      F.mid_k  coordinates_X.x  coordinates_X.y  coordinates_X.z  \\\n",
       "0         NaN              NaN              NaN              NaN   \n",
       "1         NaN              NaN              NaN              NaN   \n",
       "2         NaN              NaN              NaN              NaN   \n",
       "3         NaN              NaN              NaN              NaN   \n",
       "4         NaN              NaN              NaN              NaN   \n",
       "...       ...              ...              ...              ...   \n",
       "2198      NaN              NaN              NaN              NaN   \n",
       "2199      NaN              NaN              NaN              NaN   \n",
       "2200      NaN              NaN              NaN              NaN   \n",
       "2201      NaN              NaN              NaN              NaN   \n",
       "2202      NaN              NaN              NaN              NaN   \n",
       "\n",
       "      X.containment  X.food_k  X.strong_k  X.mid_k  \n",
       "0               NaN       NaN         NaN      NaN  \n",
       "1               NaN       NaN         NaN      NaN  \n",
       "2               NaN       NaN         NaN      NaN  \n",
       "3               NaN       NaN         NaN      NaN  \n",
       "4               NaN       NaN         NaN      NaN  \n",
       "...             ...       ...         ...      ...  \n",
       "2198            NaN       NaN         NaN      NaN  \n",
       "2199            NaN       NaN         NaN      NaN  \n",
       "2200            NaN       NaN         NaN      NaN  \n",
       "2201            NaN       NaN         NaN      NaN  \n",
       "2202            NaN       NaN         NaN      NaN  \n",
       "\n",
       "[2203 rows x 357 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "52fca39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "float_cols = df.select_dtypes(include=['float64']).columns\n",
    "df.loc[:, float_cols] = df.loc[:, float_cols].fillna(-99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "51c3d424",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.select_dtypes(include=['object'])\n",
    "for col in cols.columns.values:\n",
    "    df[col] = df[col].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f8e9acc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "p    188\n",
       "k    162\n",
       "g    160\n",
       "f    157\n",
       "c    148\n",
       "s    134\n",
       "b     78\n",
       "w     74\n",
       "o     73\n",
       "a     72\n",
       "r     47\n",
       "d     27\n",
       "h     27\n",
       "t     22\n",
       "e     22\n",
       "z     21\n",
       "m     13\n",
       "n      9\n",
       "x      2\n",
       "i      1\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()\n",
    "df[:1437]['target'].value_counts()\n",
    "#df[:1437]['target'].loc[df[:1437]['target'] == 'i'].index[0]\n",
    "#df_new[1436:]['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "af2bd3d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "727"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#index_to_drop = df[1436:]['target'].loc[df[1436:]['target'] == 'y'].index[0]\n",
    "#index_to_drop2 = df[1436:]['target'].loc[df[1436:]['target'] == 'h'].index[0]\n",
    "index_to_drop = df['target'].loc[df['target'] == 'i'].index[0]\n",
    "index_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3eebbfab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "727"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_drop2 = df_new[:1437]['target'].loc[df_new[:1437]['target'] == 'i'].index[0]\n",
    "index_to_drop2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d3401a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_of_sequences = len(df[df['input'] == '<start>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "16af1823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove row with target that only occurs once\n",
    "\n",
    "df_new = df.drop(index=[index_to_drop], axis=0)\n",
    "#df_new = df.drop(index=[index_to_drop2], axis=0)\n",
    "df_new.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5491f1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate stratified split\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=10, test_size=0.3, random_state=42)\n",
    "\n",
    "for train_index, test_index in split.split(df_new[:1436], df_new[:1436]['target']):\n",
    "#for train_index, test_index in split.split(df_new, df_new['target']):\n",
    "#for train_index, test_index in split.split(df_new[1436:], df_new[1436:]['target']):\n",
    "    strat_train = df_new.loc[train_index]\n",
    "    strat_test_val = df_new.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b13b3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "11eba3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split test_val into test and val\n",
    "\n",
    "split_test_val = len(strat_test_val)//2\n",
    "\n",
    "strat_test = strat_test_val[:split_test_val]\n",
    "strat_val = strat_test_val[split_test_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ead4a95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate list of labels to pass to MultiLabelBinarizer so there's the same number of\n",
    "# classes for all datasets\n",
    "\n",
    "labels = df_new['target'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ce71230e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2e8da447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataframe, labels, shuffle=True, batch_size=32):\n",
    "    df = dataframe.copy()\n",
    "    labels_ds = df.pop('target')\n",
    "    encoder = MultiLabelBinarizer(classes=labels)\n",
    "    encoded_labels = encoder.fit_transform(labels_ds)\n",
    "    \n",
    "    df = {key: value[:, tf.newaxis] for key, value in df.items()}\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(df), encoded_labels))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=len(dataframe))\n",
    "    \n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(batch_size)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9e6e6001",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "416e6d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14932/1510453973.py:7: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  df = {key: value[:, tf.newaxis] for key, value in df.items()}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type bool).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [95]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_ds \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrat_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m val_ds \u001b[38;5;241m=\u001b[39m create_dataset(strat_val, labels, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n\u001b[1;32m      3\u001b[0m test_ds \u001b[38;5;241m=\u001b[39m create_dataset(strat_test, labels, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n",
      "Input \u001b[0;32mIn [94]\u001b[0m, in \u001b[0;36mcreate_dataset\u001b[0;34m(dataframe, labels, shuffle, batch_size)\u001b[0m\n\u001b[1;32m      5\u001b[0m encoded_labels \u001b[38;5;241m=\u001b[39m encoder\u001b[38;5;241m.\u001b[39mfit_transform(labels_ds)\n\u001b[1;32m      7\u001b[0m df \u001b[38;5;241m=\u001b[39m {key: value[:, tf\u001b[38;5;241m.\u001b[39mnewaxis] \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m----> 8\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_tensor_slices\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoded_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[1;32m     10\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mshuffle(buffer_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(dataframe))\n",
      "File \u001b[0;32m~/anaconda3/envs/tf2.7/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:781\u001b[0m, in \u001b[0;36mDatasetV2.from_tensor_slices\u001b[0;34m(tensors, name)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_tensor_slices\u001b[39m(tensors, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    705\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a `Dataset` whose elements are slices of the given tensors.\u001b[39;00m\n\u001b[1;32m    706\u001b[0m \n\u001b[1;32m    707\u001b[0m \u001b[38;5;124;03m  The given tensors are sliced along their first dimension. This operation\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;124;03m    Dataset: A `Dataset`.\u001b[39;00m\n\u001b[1;32m    780\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 781\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTensorSliceDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf2.7/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:4661\u001b[0m, in \u001b[0;36mTensorSliceDataset.__init__\u001b[0;34m(self, element, is_files, name)\u001b[0m\n\u001b[1;32m   4659\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, element, is_files\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   4660\u001b[0m   \u001b[38;5;124;03m\"\"\"See `Dataset.from_tensor_slices()` for details.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 4661\u001b[0m   element \u001b[38;5;241m=\u001b[39m \u001b[43mstructure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43melement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4662\u001b[0m   batched_spec \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mtype_spec_from_value(element)\n\u001b[1;32m   4663\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensors \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_batched_tensor_list(batched_spec, element)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf2.7/lib/python3.10/site-packages/tensorflow/python/data/util/structure.py:129\u001b[0m, in \u001b[0;36mnormalize_element\u001b[0;34m(element, element_signature)\u001b[0m\n\u001b[1;32m    126\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    127\u001b[0m         dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(spec, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    128\u001b[0m         normalized_components\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 129\u001b[0m             \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcomponent_\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m nest\u001b[38;5;241m.\u001b[39mpack_sequence_as(pack_as, normalized_components)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf2.7/lib/python3.10/site-packages/tensorflow/python/profiler/trace.py:163\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf2.7/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1621\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1616\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconvert_to_tensor did not convert to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1617\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe preferred dtype: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m vs \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1618\u001b[0m                       (ret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype, preferred_dtype\u001b[38;5;241m.\u001b[39mbase_dtype))\n\u001b[1;32m   1620\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1621\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1623\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m   1624\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf2.7/lib/python3.10/site-packages/tensorflow/python/framework/tensor_conversion_registry.py:52\u001b[0m, in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_default_conversion_function\u001b[39m(value, dtype, name, as_ref):\n\u001b[1;32m     51\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m as_ref  \u001b[38;5;66;03m# Unused.\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf2.7/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:271\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    176\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 271\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf2.7/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:283\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.constant\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    282\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m--> 283\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_eager_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m g \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mget_default_graph()\n\u001b[1;32m    286\u001b[0m tensor_value \u001b[38;5;241m=\u001b[39m attr_value_pb2\u001b[38;5;241m.\u001b[39mAttrValue()\n",
      "File \u001b[0;32m~/anaconda3/envs/tf2.7/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:308\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[1;32m    307\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 308\u001b[0m   t \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_eager_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    309\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m~/anaconda3/envs/tf2.7/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:106\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    104\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    105\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type bool)."
     ]
    }
   ],
   "source": [
    "train_ds = create_dataset(strat_train, labels, batch_size=batch_size)\n",
    "val_ds = create_dataset(strat_val, labels, shuffle=False, batch_size=batch_size)\n",
    "test_ds = create_dataset(strat_test, labels, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb42795",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f4db47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalization_layer(name, dataset):\n",
    "  # Create a Normalization layer for the feature.\n",
    "    normalizer = layers.Normalization(axis=None)\n",
    "\n",
    "  # Prepare a Dataset that only yields the feature.\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "\n",
    "  # Learn the statistics of the data.\n",
    "    normalizer.adapt(feature_ds)\n",
    "    \n",
    "    return normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597f7ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_encoding_layer(name, dataset, dtype, max_tokens=None):\n",
    "    if dtype == 'string':\n",
    "        index = layers.StringLookup(max_tokens=max_tokens)\n",
    "    else:\n",
    "        index = layers.IntegerLookup(max_tokens=max_tokens)\n",
    "        \n",
    "    # prepare tf.data.Dataset that only yields the feature    \n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    \n",
    "    # learn set of possible values and assign fixed int index\n",
    "    index.adapt(feature_ds)\n",
    "    \n",
    "    # encode int indices\n",
    "    encoder = layers.CategoryEncoding(num_tokens=index.vocabulary_size())\n",
    "    \n",
    "    # apply multi-hot encoding to indices\n",
    "    # lambda function captures the layer to include them in Keras functional models later\n",
    "    return lambda feature: encoder(index(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce78468",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_data(dataframe):\n",
    "    all_inputs = []\n",
    "    encoded_features = []\n",
    "    \n",
    "    for header in dataframe.columns:\n",
    "        # numerical features\n",
    "        if 'coord' in header or 'already' in header:\n",
    "            numeric_col = tf.keras.Input(shape=(1,), name=header)\n",
    "            normalization_layer = get_normalization_layer(header, train_ds)\n",
    "            encoded_numeric_col = normalization_layer(numeric_col)\n",
    "            all_inputs.append(numeric_col)\n",
    "            encoded_features.append(encoded_numeric_col)\n",
    "        \n",
    "        # categorical features\n",
    "        elif 'containment' in header or 'food' in header or 'mid' in header or \\\n",
    "        'strong' in header:\n",
    "            categorical_col = tf.keras.Input(shape=(1,), name=header, dtype='int64')\n",
    "            encoding_layer = get_category_encoding_layer(name=header,\n",
    "                                                        dataset=train_ds,\n",
    "                                                        dtype='int64')\n",
    "            encoded_categorical_col = encoding_layer(categorical_col)\n",
    "            all_inputs.append(categorical_col)\n",
    "            encoded_features.append(encoded_categorical_col)\n",
    "            \n",
    "        elif header == 'input':\n",
    "            categorical_col = tf.keras.Input(shape=(1,), name='input', dtype='string')\n",
    "            encoding_layer = get_category_encoding_layer(name='input',\n",
    "                                                        dataset=train_ds,\n",
    "                                                        dtype='string')\n",
    "            encoded_categorical_col = encoding_layer(categorical_col)\n",
    "            all_inputs.append(categorical_col)\n",
    "            encoded_features.append(encoded_categorical_col)\n",
    "            \n",
    "    return all_inputs, encoded_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d333498",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_inputs, encoded_features = create_input_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2de5cf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5caa2ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use model from tutorial with dense layers\n",
    "\n",
    "all_features = tf.keras.layers.concatenate(encoded_features)\n",
    "x = tf.keras.layers.Dense(512, activation=\"relu\")(all_features)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(256, activation=\"relu\")(all_features)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "output = tf.keras.layers.Dense(len(labels))(x)\n",
    "\n",
    "model = tf.keras.Model(all_inputs, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c1736d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5f1f8941",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.keras.utils.plot_model(model, show_shapes=True, rankdir='LR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9dee9ed0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 1.2524 - accuracy: 0.5753 - val_loss: 0.8404 - val_accuracy: 0.7500\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 1.1802 - accuracy: 0.5775 - val_loss: 0.8513 - val_accuracy: 0.7604\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 1.1627 - accuracy: 0.5933 - val_loss: 0.8720 - val_accuracy: 0.7604\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 1.1465 - accuracy: 0.6000 - val_loss: 0.8834 - val_accuracy: 0.7500\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 1.1316 - accuracy: 0.5798 - val_loss: 0.8862 - val_accuracy: 0.7500\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.0938 - accuracy: 0.6270 - val_loss: 0.8808 - val_accuracy: 0.7292\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 1.1342 - accuracy: 0.5865 - val_loss: 0.8724 - val_accuracy: 0.7292\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 1.1437 - accuracy: 0.5910 - val_loss: 0.8908 - val_accuracy: 0.7188\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 1.1250 - accuracy: 0.6112 - val_loss: 0.8988 - val_accuracy: 0.7292\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.0338 - accuracy: 0.6472 - val_loss: 0.9038 - val_accuracy: 0.7396\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 1.1053 - accuracy: 0.6022 - val_loss: 0.8951 - val_accuracy: 0.6979\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 1.0876 - accuracy: 0.6067 - val_loss: 0.8921 - val_accuracy: 0.6979\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 1.0736 - accuracy: 0.6315 - val_loss: 0.9071 - val_accuracy: 0.7083\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 1.0721 - accuracy: 0.6247 - val_loss: 0.9185 - val_accuracy: 0.7083\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.0800 - accuracy: 0.6360 - val_loss: 0.9211 - val_accuracy: 0.6979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f174b5f2950>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, epochs=100, validation_data=val_ds, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "08a2e3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 69ms/step - loss: 1.0930 - accuracy: 0.6526\n",
      "Accuracy 0.6526315808296204\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print(\"Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b58dd68b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-07 10:03:41.886830: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Function `_wrapped_model` contains input name(s) start_coords.x, start_coords.y, start_coords.z, p.already_seen, n.already_seen, w.already_seen, t.already_seen, g.already_seen, b.already_seen, q.already_seen, d.already_seen, h.already_seen, y.already_seen, i.already_seen, e.already_seen, a.already_seen, x.already_seen, z.already_seen, s.already_seen, o.already_seen, u.already_seen, m.already_seen, c.already_seen, f.already_seen, r.already_seen, k.already_seen, v.already_seen, coordinates_p.x, coordinates_p.y, coordinates_p.z, p.containment, p.food_k, p.strong_k, p.mid_k, coordinates_o.x, coordinates_o.y, coordinates_o.z, o.containment, o.food_k, o.strong_k, o.mid_k, coordinates_c.x, coordinates_c.y, coordinates_c.z, c.containment, c.food_k, c.strong_k, c.mid_k, coordinates_g.x, coordinates_g.y, coordinates_g.z, g.containment, g.food_k, g.strong_k, g.mid_k, coordinates_k.x, coordinates_k.y, coordinates_k.z, k.containment, k.food_k, k.strong_k, k.mid_k, coordinates_r.x, coordinates_r.y, coordinates_r.z, r.containment, r.food_k, r.strong_k, r.mid_k, coordinates_w.x, coordinates_w.y, coordinates_w.z, w.containment, w.food_k, w.strong_k, w.mid_k, coordinates_f.x, coordinates_f.y, coordinates_f.z, f.containment, f.food_k, f.strong_k, f.mid_k, coordinates_s.x, coordinates_s.y, coordinates_s.z, s.containment, s.food_k, s.strong_k, s.mid_k, coordinates_t.x, coordinates_t.y, coordinates_t.z, t.containment, t.food_k, t.strong_k, t.mid_k, coordinates_e.x, coordinates_e.y, coordinates_e.z, e.containment, e.food_k, e.strong_k, e.mid_k, coordinates_n.x, coordinates_n.y, coordinates_n.z, n.containment, n.food_k, n.strong_k, n.mid_k, coordinates_z.x, coordinates_z.y, coordinates_z.z, z.containment, z.food_k, z.strong_k, z.mid_k, coordinates_m.x, coordinates_m.y, coordinates_m.z, m.containment, m.food_k, m.strong_k, m.mid_k, coordinates_x.x, coordinates_x.y, coordinates_x.z, x.containment, x.food_k, x.strong_k, x.mid_k, coordinates_i.x, coordinates_i.y, coordinates_i.z, i.containment, i.food_k, i.strong_k, i.mid_k, coordinates_h.x, coordinates_h.y, coordinates_h.z, h.containment, h.food_k, h.strong_k, h.mid_k, coordinates_b.x, coordinates_b.y, coordinates_b.z, b.containment, b.food_k, b.strong_k, b.mid_k, coordinates_a.x, coordinates_a.y, coordinates_a.z, a.containment, a.food_k, a.strong_k, a.mid_k, coordinates_d.x, coordinates_d.y, coordinates_d.z, d.containment, d.food_k, d.strong_k, d.mid_k, coordinates_u.x, coordinates_u.y, coordinates_u.z, u.containment, u.food_k, u.strong_k, u.mid_k, coordinates_q.x, coordinates_q.y, coordinates_q.z, q.containment, q.food_k, q.strong_k, q.mid_k, coordinates_v.x, coordinates_v.y, coordinates_v.z, v.containment, v.food_k, v.strong_k, v.mid_k, coordinates_y.x, coordinates_y.y, coordinates_y.z, y.containment, y.food_k, y.strong_k, y.mid_k with unsupported characters which will be renamed to start_coords_x, start_coords_y, start_coords_z, p_already_seen, n_already_seen, w_already_seen, t_already_seen, g_already_seen, b_already_seen, q_already_seen, d_already_seen, h_already_seen, y_already_seen, i_already_seen, e_already_seen, a_already_seen, x_already_seen, z_already_seen, s_already_seen, o_already_seen, u_already_seen, m_already_seen, c_already_seen, f_already_seen, r_already_seen, k_already_seen, v_already_seen, coordinates_p_x, coordinates_p_y, coordinates_p_z, p_containment, p_food_k, p_strong_k, p_mid_k, coordinates_o_x, coordinates_o_y, coordinates_o_z, o_containment, o_food_k, o_strong_k, o_mid_k, coordinates_c_x, coordinates_c_y, coordinates_c_z, c_containment, c_food_k, c_strong_k, c_mid_k, coordinates_g_x, coordinates_g_y, coordinates_g_z, g_containment, g_food_k, g_strong_k, g_mid_k, coordinates_k_x, coordinates_k_y, coordinates_k_z, k_containment, k_food_k, k_strong_k, k_mid_k, coordinates_r_x, coordinates_r_y, coordinates_r_z, r_containment, r_food_k, r_strong_k, r_mid_k, coordinates_w_x, coordinates_w_y, coordinates_w_z, w_containment, w_food_k, w_strong_k, w_mid_k, coordinates_f_x, coordinates_f_y, coordinates_f_z, f_containment, f_food_k, f_strong_k, f_mid_k, coordinates_s_x, coordinates_s_y, coordinates_s_z, s_containment, s_food_k, s_strong_k, s_mid_k, coordinates_t_x, coordinates_t_y, coordinates_t_z, t_containment, t_food_k, t_strong_k, t_mid_k, coordinates_e_x, coordinates_e_y, coordinates_e_z, e_containment, e_food_k, e_strong_k, e_mid_k, coordinates_n_x, coordinates_n_y, coordinates_n_z, n_containment, n_food_k, n_strong_k, n_mid_k, coordinates_z_x, coordinates_z_y, coordinates_z_z, z_containment, z_food_k, z_strong_k, z_mid_k, coordinates_m_x, coordinates_m_y, coordinates_m_z, m_containment, m_food_k, m_strong_k, m_mid_k, coordinates_x_x, coordinates_x_y, coordinates_x_z, x_containment, x_food_k, x_strong_k, x_mid_k, coordinates_i_x, coordinates_i_y, coordinates_i_z, i_containment, i_food_k, i_strong_k, i_mid_k, coordinates_h_x, coordinates_h_y, coordinates_h_z, h_containment, h_food_k, h_strong_k, h_mid_k, coordinates_b_x, coordinates_b_y, coordinates_b_z, b_containment, b_food_k, b_strong_k, b_mid_k, coordinates_a_x, coordinates_a_y, coordinates_a_z, a_containment, a_food_k, a_strong_k, a_mid_k, coordinates_d_x, coordinates_d_y, coordinates_d_z, d_containment, d_food_k, d_strong_k, d_mid_k, coordinates_u_x, coordinates_u_y, coordinates_u_z, u_containment, u_food_k, u_strong_k, u_mid_k, coordinates_q_x, coordinates_q_y, coordinates_q_z, q_containment, q_food_k, q_strong_k, q_mid_k, coordinates_v_x, coordinates_v_y, coordinates_v_z, v_containment, v_food_k, v_strong_k, v_mid_k, coordinates_y_x, coordinates_y_y, coordinates_y_z, y_containment, y_food_k, y_strong_k, y_mid_k in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/next_obj_classifier_tablesetting_2022-06-07/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/next_obj_classifier_tablesetting_2022-06-07/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('models/next_obj_classifier_tablesetting_2022-06-07')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e33c5a49",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-29 13:44:36.463151: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-29 13:44:36.525754: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-29 13:44:36.526018: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-29 13:44:36.526328: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-29 13:44:36.526681: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-29 13:44:36.526921: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-29 13:44:36.527033: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-29 13:44:36.907644: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-29 13:44:36.907788: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-29 13:44:36.907892: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-29 13:44:36.907975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6306 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1070 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "reloaded_model = tf.keras.models.load_model('models/next_obj_classifier_tablesetting_2022-06-07/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a6bfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test prediction for one sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b50493d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df.loc[0].drop('target').to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "63d9fe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dict = {name: tf.convert_to_tensor([value]) for name, value in sample.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2e68164e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = reloaded_model.predict(input_dict)\n",
    "prediction = tf.nn.sigmoid(prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad905aed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "27161320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'p'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get label for prediction\n",
    "\n",
    "pred_label = labels[np.argmax(prediction)]\n",
    "pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae9f505d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prequential_error(dataframe, model, labels, nr_of_sequences):\n",
    "    errors = [[] for seq in range(0, nr_of_sequences + 1)]\n",
    "    predictions = [[] for seq in range(0, nr_of_sequences)]\n",
    "    start_token_count = 0\n",
    "    sequence_nr = 0\n",
    "    \n",
    "    for row in trange(dataframe.index[0], dataframe.index[-1]): \n",
    "        observed_target = dataframe.loc[row, 'target']\n",
    "        sample = dataframe.loc[row].drop('target').to_dict()\n",
    "        input_dict = {name: tf.convert_to_tensor([value]) for name, value in \n",
    "                          sample.items()}\n",
    "        predicted_target = model.predict(input_dict)\n",
    "        predicted_target = tf.nn.sigmoid(predicted_target[0])\n",
    "            \n",
    "        pred_label = labels[np.argmax(predicted_target)]\n",
    "        error = 1 - damerauLevenshtein(pred_label, observed_target)\n",
    "        errors[sequence_nr].append(error)\n",
    "        predictions[sequence_nr].append(pred_label)\n",
    "        \n",
    "        if row != 0 and dataframe.loc[row, 'input'] == '<start>':\n",
    "            start_token_count += 1\n",
    "        \n",
    "        if start_token_count > 0:\n",
    "            sequence_nr += 1\n",
    "            start_token_count = 0\n",
    "            \n",
    "    return errors, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a4e023",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d1703362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2073"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[1438:].index[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7ae2385",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2073/2073 [11:49<00:00,  2.92it/s]\n"
     ]
    }
   ],
   "source": [
    "errors, predictions = get_prequential_error(df, reloaded_model, labels, nr_of_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3eacff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "summed_error = [sum(error) for error in errors[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28e4a79e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(summed_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9edef143",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/nn_spatialinfo_prequential_summed_fitted_on_ts_results_all_2022-06-07.txt', 'w') as file:\n",
    "    file.write(str(summed_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "56cf9a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.466019417475728"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(summed_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2d578e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1adf9d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['fitted_on_cooking_all'] = summed_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "35b142e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ids = pd.read_csv('../../opportunistic_planning/all_lowest_error/all_task_environments_list_2022-06-02_unique_sequences.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60cd561",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "650148de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fitted_on_ts_all</th>\n",
       "      <th>fitted_on_all_all</th>\n",
       "      <th>ID</th>\n",
       "      <th>fitted_on_cooking_all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>a1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>a3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>a5</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>a11</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a13</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>s37-d21</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>s37-d25</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>s37-d29</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>s37-d39</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>s37-d46</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>309 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     fitted_on_ts_all  fitted_on_all_all       ID  fitted_on_cooking_all\n",
       "0                 1.0                1.0       a1                    2.0\n",
       "1                 4.0                3.0       a3                    2.0\n",
       "2                 3.0                3.0       a5                    3.0\n",
       "3                 8.0                8.0      a11                    8.0\n",
       "4                 2.0                0.0      a13                    1.0\n",
       "..                ...                ...      ...                    ...\n",
       "304               6.0                5.0  s37-d21                    5.0\n",
       "305               3.0                3.0  s37-d25                    3.0\n",
       "306               4.0                3.0  s37-d29                    3.0\n",
       "307               8.0                6.0  s37-d39                    6.0\n",
       "308               3.0                3.0  s37-d46                    3.0\n",
       "\n",
       "[309 rows x 4 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6e0f747e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('results/nn_spatialinfo_prequential_fitting_variants_2022-06-23.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "905c2066",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df = pd.read_csv('results/predictions_comparison_2022-06-29.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "add22029",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [''.join(lst) for lst in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b58e61c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df['nn_fitted_ts'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f2f34c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df['ID'] = df_ids['ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d30b944b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df.to_csv('results/predictions_comparison_2022-06-29.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8dbf6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.7",
   "language": "python",
   "name": "tf2.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
