{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8da2a4b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from fastDamerauLevenshtein import damerauLevenshtein\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
    "from tensorflow.keras import layers\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f06a6ff",
   "metadata": {},
   "source": [
    "## 1. Read + prepare data\n",
    "Data is expected to be transformed into a single-step version using the `transform_data_to_single_step_workflow.py` script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49e7518e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/single_step_df_ints_2022-10-11_encoded.csv', header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94fb5be",
   "metadata": {},
   "source": [
    "Float columns: Fill NAs with -99."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52fca39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "float_cols = df.select_dtypes(include=['float64']).columns\n",
    "df.loc[:, float_cols] = df.loc[:, float_cols].fillna(-99)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c62c48",
   "metadata": {},
   "source": [
    "Object columns: Fill NAs with empty string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51c3d424",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.select_dtypes(include=['object'])\n",
    "for col in cols.columns.values:\n",
    "    df[col] = df[col].fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218b6bbd",
   "metadata": {},
   "source": [
    "Show value counts for target to check if all classes have more than one instance (required for stratisfied shuffle split)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f8e9acc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "p    188\n",
       "k    162\n",
       "g    160\n",
       "f    157\n",
       "c    148\n",
       "s    134\n",
       "b     78\n",
       "w     74\n",
       "o     73\n",
       "a     72\n",
       "r     47\n",
       "d     27\n",
       "h     27\n",
       "t     22\n",
       "e     22\n",
       "z     21\n",
       "m     13\n",
       "n      9\n",
       "x      2\n",
       "i      1\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()\n",
    "df[:1437]['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0c0f90",
   "metadata": {},
   "source": [
    "Remove row with class that only occurs once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "af2bd3d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "727"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_drop = df['target'].loc[df['target'] == 'i'].index[0]\n",
    "index_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d3401a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_of_sequences = len(df[df['input'] == '<start>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "16af1823",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df.drop(index=[index_to_drop], axis=0)\n",
    "df_new.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d9d11d",
   "metadata": {},
   "source": [
    "Use stratisfied shuffle split to generate training and test set. The dataframe is cut at index 1436 here to only use the table setting data for training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5491f1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = StratifiedShuffleSplit(n_splits=10, test_size=0.3, random_state=42)\n",
    "\n",
    "for train_index, test_index in split.split(df_new[:1436], df_new[:1436]['target']):\n",
    "    strat_train = df_new.loc[train_index]\n",
    "    strat_test_val = df_new.loc[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c7db30",
   "metadata": {},
   "source": [
    "Split test data into test and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "11eba3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_test_val = len(strat_test_val)//2\n",
    "\n",
    "strat_test = strat_test_val[:split_test_val]\n",
    "strat_val = strat_test_val[split_test_val:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aaa271e",
   "metadata": {},
   "source": [
    "Generate list of labels to pass to MultiLabelBinarizer so there's the same number of classes for all datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ead4a95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df_new['target'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ce71230e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f4e934",
   "metadata": {},
   "source": [
    "## 2. Create train, test, validation data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2e8da447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataframe, labels, shuffle=True, batch_size=32):\n",
    "    df = dataframe.copy()\n",
    "    labels_ds = df.pop('target')\n",
    "    encoder = MultiLabelBinarizer(classes=labels)\n",
    "    encoded_labels = encoder.fit_transform(labels_ds)\n",
    "    \n",
    "    df = {key: value[:, tf.newaxis] for key, value in df.items()}\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(df), encoded_labels))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=len(dataframe))\n",
    "    \n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(batch_size)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9e6e6001",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "416e6d06",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_63205/1510453973.py:7: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  df = {key: value[:, tf.newaxis] for key, value in df.items()}\n",
      "2023-08-08 11:21:49.904040: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-08 11:21:50.019249: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-08 11:21:50.019423: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-08 11:21:50.021962: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-08 11:21:50.023020: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-08 11:21:50.023263: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-08 11:21:50.023542: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-08 11:21:51.226244: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-08 11:21:51.226417: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-08 11:21:51.226546: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-08 11:21:51.227012: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5771 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1070 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "train_ds = create_dataset(strat_train, labels, batch_size=batch_size)\n",
    "val_ds = create_dataset(strat_val, labels, shuffle=False, batch_size=batch_size)\n",
    "test_ds = create_dataset(strat_test, labels, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfccf05",
   "metadata": {},
   "source": [
    "## 3. Define functions to create layers and input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06f4db47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalization_layer(name, dataset):\n",
    "  # create a normalization layer for the feature\n",
    "    normalizer = layers.Normalization(axis=None)\n",
    "\n",
    "  # prepare a dataset that only yields the feature\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "\n",
    "  # learn the statistics of the data\n",
    "    normalizer.adapt(feature_ds)\n",
    "    \n",
    "    return normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "597f7ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_encoding_layer(name, dataset, dtype, max_tokens=None):\n",
    "    if dtype == 'string':\n",
    "        index = layers.StringLookup(max_tokens=max_tokens)\n",
    "    else:\n",
    "        index = layers.IntegerLookup(max_tokens=max_tokens)\n",
    "        \n",
    "    # prepare tf.data.Dataset that only yields the feature    \n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    \n",
    "    # learn set of possible values and assign fixed int index\n",
    "    index.adapt(feature_ds)\n",
    "    \n",
    "    # encode int indices\n",
    "    encoder = layers.CategoryEncoding(num_tokens=index.vocabulary_size())\n",
    "    \n",
    "    # apply multi-hot encoding to indices\n",
    "    # lambda function captures the layer to include them in Keras functional models later\n",
    "    return lambda feature: encoder(index(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ce78468",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_data(dataframe):\n",
    "    all_inputs = []\n",
    "    encoded_features = []\n",
    "    \n",
    "    for header in dataframe.columns:\n",
    "        # numerical features\n",
    "        if 'coord' in header or 'already' in header:\n",
    "            numeric_col = tf.keras.Input(shape=(1,), name=header)\n",
    "            normalization_layer = get_normalization_layer(header, train_ds)\n",
    "            encoded_numeric_col = normalization_layer(numeric_col)\n",
    "            all_inputs.append(numeric_col)\n",
    "            encoded_features.append(encoded_numeric_col)\n",
    "        \n",
    "        # categorical features\n",
    "        elif 'containment' in header or 'food' in header or 'mid' in header or \\\n",
    "        'strong' in header:\n",
    "            categorical_col = tf.keras.Input(shape=(1,), name=header, dtype='int64')\n",
    "            encoding_layer = get_category_encoding_layer(name=header,\n",
    "                                                        dataset=train_ds,\n",
    "                                                        dtype='int64')\n",
    "            encoded_categorical_col = encoding_layer(categorical_col)\n",
    "            all_inputs.append(categorical_col)\n",
    "            encoded_features.append(encoded_categorical_col)\n",
    "            \n",
    "        elif header == 'input':\n",
    "            categorical_col = tf.keras.Input(shape=(1,), name='input', dtype='string')\n",
    "            encoding_layer = get_category_encoding_layer(name='input',\n",
    "                                                        dataset=train_ds,\n",
    "                                                        dtype='string')\n",
    "            encoded_categorical_col = encoding_layer(categorical_col)\n",
    "            all_inputs.append(categorical_col)\n",
    "            encoded_features.append(encoded_categorical_col)\n",
    "            \n",
    "    return all_inputs, encoded_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2cef52",
   "metadata": {},
   "source": [
    "## 4. Create and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d333498",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_inputs, encoded_features = create_input_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2de5cf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5caa2ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = tf.keras.layers.concatenate(encoded_features)\n",
    "x = tf.keras.layers.Dense(512, activation=\"relu\")(all_features)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(256, activation=\"relu\")(all_features)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "output = tf.keras.layers.Dense(len(labels))(x)\n",
    "\n",
    "model = tf.keras.Model(all_inputs, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c1736d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9dee9ed0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "8/8 [==============================] - 10s 645ms/step - loss: 3.2042 - accuracy: 0.1005 - val_loss: 18419.6328 - val_accuracy: 0.1667\n",
      "Epoch 2/300\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 2.5637 - accuracy: 0.1642 - val_loss: 18800.8965 - val_accuracy: 0.2778\n",
      "Epoch 3/300\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 2.3951 - accuracy: 0.1930 - val_loss: 19622.0859 - val_accuracy: 0.2824\n",
      "Epoch 4/300\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 2.2580 - accuracy: 0.2020 - val_loss: 19102.6152 - val_accuracy: 0.3148\n",
      "Epoch 5/300\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 2.1455 - accuracy: 0.2537 - val_loss: 19582.5605 - val_accuracy: 0.3287\n",
      "Epoch 6/300\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 2.0425 - accuracy: 0.2826 - val_loss: 19966.5527 - val_accuracy: 0.3843\n",
      "Epoch 7/300\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 1.9768 - accuracy: 0.3095 - val_loss: 20775.7090 - val_accuracy: 0.4074\n",
      "Epoch 8/300\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 1.9535 - accuracy: 0.3124 - val_loss: 20855.4160 - val_accuracy: 0.4444\n",
      "Epoch 9/300\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 1.9246 - accuracy: 0.3343 - val_loss: 21187.8379 - val_accuracy: 0.4444\n",
      "Epoch 10/300\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 1.8673 - accuracy: 0.3363 - val_loss: 21331.6582 - val_accuracy: 0.4491\n",
      "Epoch 11/300\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 1.8113 - accuracy: 0.3493 - val_loss: 22502.9648 - val_accuracy: 0.4352\n",
      "Epoch 12/300\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 1.7836 - accuracy: 0.3423 - val_loss: 21901.9609 - val_accuracy: 0.4769\n",
      "Epoch 13/300\n",
      "8/8 [==============================] - 1s 124ms/step - loss: 1.7385 - accuracy: 0.3930 - val_loss: 22120.8926 - val_accuracy: 0.4259\n",
      "Epoch 14/300\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 1.7326 - accuracy: 0.3841 - val_loss: 22266.1523 - val_accuracy: 0.4769\n",
      "Epoch 15/300\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 1.6592 - accuracy: 0.4010 - val_loss: 22883.3145 - val_accuracy: 0.4722\n",
      "Epoch 16/300\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 1.6398 - accuracy: 0.4249 - val_loss: 23619.5391 - val_accuracy: 0.4954\n",
      "Epoch 17/300\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 1.6249 - accuracy: 0.4279 - val_loss: 23793.9551 - val_accuracy: 0.4954\n",
      "Epoch 18/300\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 1.5875 - accuracy: 0.4507 - val_loss: 24077.1973 - val_accuracy: 0.5000\n",
      "Epoch 19/300\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 1.5430 - accuracy: 0.4527 - val_loss: 23170.9707 - val_accuracy: 0.5417\n",
      "Epoch 20/300\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 1.5515 - accuracy: 0.4478 - val_loss: 23860.1895 - val_accuracy: 0.5231\n",
      "Epoch 21/300\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 1.5273 - accuracy: 0.4577 - val_loss: 24228.5156 - val_accuracy: 0.5509\n",
      "Epoch 22/300\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 1.5010 - accuracy: 0.4736 - val_loss: 24201.2969 - val_accuracy: 0.5231\n",
      "Epoch 23/300\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 1.4840 - accuracy: 0.4766 - val_loss: 24209.1875 - val_accuracy: 0.5000\n",
      "Epoch 24/300\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 1.4766 - accuracy: 0.4796 - val_loss: 24138.7793 - val_accuracy: 0.5231\n",
      "Epoch 25/300\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 1.4533 - accuracy: 0.4846 - val_loss: 24492.7285 - val_accuracy: 0.5278\n",
      "Epoch 26/300\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 1.4133 - accuracy: 0.4955 - val_loss: 24709.8223 - val_accuracy: 0.5556\n",
      "Epoch 27/300\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 1.3940 - accuracy: 0.5045 - val_loss: 25553.1953 - val_accuracy: 0.5417\n",
      "Epoch 28/300\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 1.4039 - accuracy: 0.4975 - val_loss: 25208.8457 - val_accuracy: 0.5463\n",
      "Epoch 29/300\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 1.3566 - accuracy: 0.5164 - val_loss: 25850.5352 - val_accuracy: 0.5370\n",
      "Epoch 30/300\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 1.3792 - accuracy: 0.5095 - val_loss: 25431.3047 - val_accuracy: 0.5741\n",
      "Epoch 31/300\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 1.3609 - accuracy: 0.5144 - val_loss: 27257.4746 - val_accuracy: 0.5787\n",
      "Epoch 32/300\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 1.3305 - accuracy: 0.5303 - val_loss: 27107.5293 - val_accuracy: 0.5787\n",
      "Epoch 33/300\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 1.3688 - accuracy: 0.5204 - val_loss: 27204.0137 - val_accuracy: 0.5556\n",
      "Epoch 34/300\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 1.3233 - accuracy: 0.5403 - val_loss: 27163.9590 - val_accuracy: 0.5556\n",
      "Epoch 35/300\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 1.2809 - accuracy: 0.5572 - val_loss: 26342.5176 - val_accuracy: 0.5556\n",
      "Epoch 36/300\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 1.2668 - accuracy: 0.5512 - val_loss: 27100.7969 - val_accuracy: 0.5694\n",
      "Epoch 37/300\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 1.2986 - accuracy: 0.5493 - val_loss: 26821.0098 - val_accuracy: 0.5509\n",
      "Epoch 38/300\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 1.3049 - accuracy: 0.5313 - val_loss: 26587.0410 - val_accuracy: 0.5648\n",
      "Epoch 39/300\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 1.2504 - accuracy: 0.5483 - val_loss: 27518.1602 - val_accuracy: 0.5694\n",
      "Epoch 40/300\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 1.2379 - accuracy: 0.5652 - val_loss: 28009.6914 - val_accuracy: 0.5648\n",
      "Epoch 41/300\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 1.2583 - accuracy: 0.5214 - val_loss: 27841.5137 - val_accuracy: 0.5463\n",
      "Epoch 42/300\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 1.2285 - accuracy: 0.5711 - val_loss: 27750.2520 - val_accuracy: 0.5787\n",
      "Epoch 43/300\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 1.2588 - accuracy: 0.5542 - val_loss: 27469.0000 - val_accuracy: 0.5694\n",
      "Epoch 44/300\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 1.2254 - accuracy: 0.5910 - val_loss: 27934.7637 - val_accuracy: 0.5463\n",
      "Epoch 45/300\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 1.2043 - accuracy: 0.5731 - val_loss: 28436.4141 - val_accuracy: 0.5648\n",
      "Epoch 46/300\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 1.2108 - accuracy: 0.5592 - val_loss: 27867.6035 - val_accuracy: 0.5741\n",
      "Epoch 47/300\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 1.2199 - accuracy: 0.5632 - val_loss: 27960.2637 - val_accuracy: 0.5787\n",
      "Epoch 48/300\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 1.1953 - accuracy: 0.5721 - val_loss: 28007.6641 - val_accuracy: 0.5694\n",
      "Epoch 49/300\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 1.1691 - accuracy: 0.6020 - val_loss: 28382.3574 - val_accuracy: 0.5417\n",
      "Epoch 50/300\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 1.1696 - accuracy: 0.5841 - val_loss: 28010.9727 - val_accuracy: 0.5787\n",
      "Epoch 51/300\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 1.1679 - accuracy: 0.5930 - val_loss: 28333.3535 - val_accuracy: 0.5833\n",
      "Epoch 52/300\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 1.1768 - accuracy: 0.5801 - val_loss: 27963.2051 - val_accuracy: 0.5880\n",
      "Epoch 53/300\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 1.1319 - accuracy: 0.6010 - val_loss: 28640.5742 - val_accuracy: 0.5648\n",
      "Epoch 54/300\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 1.1411 - accuracy: 0.5771 - val_loss: 27447.8711 - val_accuracy: 0.5648\n",
      "Epoch 55/300\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 1.1452 - accuracy: 0.5801 - val_loss: 28690.3105 - val_accuracy: 0.5602\n",
      "Epoch 56/300\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 1.1311 - accuracy: 0.6000 - val_loss: 27907.2148 - val_accuracy: 0.5741\n",
      "Epoch 57/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 85ms/step - loss: 1.1194 - accuracy: 0.5940 - val_loss: 29033.6973 - val_accuracy: 0.5880\n",
      "Epoch 58/300\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 1.1339 - accuracy: 0.5950 - val_loss: 27920.9102 - val_accuracy: 0.5833\n",
      "Epoch 59/300\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 1.1328 - accuracy: 0.5801 - val_loss: 28446.2363 - val_accuracy: 0.5694\n",
      "Epoch 60/300\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 1.1318 - accuracy: 0.5940 - val_loss: 28352.6836 - val_accuracy: 0.5787\n",
      "Epoch 61/300\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 1.1054 - accuracy: 0.6040 - val_loss: 29533.9844 - val_accuracy: 0.5648\n",
      "Epoch 62/300\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 1.1279 - accuracy: 0.6030 - val_loss: 29199.4512 - val_accuracy: 0.5926\n",
      "Epoch 63/300\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 1.1321 - accuracy: 0.5930 - val_loss: 29983.6973 - val_accuracy: 0.5833\n",
      "Epoch 64/300\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 1.1012 - accuracy: 0.6129 - val_loss: 29582.7715 - val_accuracy: 0.5556\n",
      "Epoch 65/300\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 1.1212 - accuracy: 0.5980 - val_loss: 29871.9082 - val_accuracy: 0.5556\n",
      "Epoch 66/300\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 1.0662 - accuracy: 0.6159 - val_loss: 29604.8105 - val_accuracy: 0.5648\n",
      "Epoch 67/300\n",
      "8/8 [==============================] - 1s 124ms/step - loss: 1.0497 - accuracy: 0.6199 - val_loss: 30355.2520 - val_accuracy: 0.5694\n",
      "Epoch 68/300\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 1.0570 - accuracy: 0.6338 - val_loss: 29740.9531 - val_accuracy: 0.5694\n",
      "Epoch 69/300\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 1.0906 - accuracy: 0.6209 - val_loss: 29399.1074 - val_accuracy: 0.5833\n",
      "Epoch 70/300\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 1.0840 - accuracy: 0.6000 - val_loss: 30127.4883 - val_accuracy: 0.5694\n",
      "Epoch 71/300\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 1.0637 - accuracy: 0.5970 - val_loss: 29825.2598 - val_accuracy: 0.5741\n",
      "Epoch 72/300\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 1.0797 - accuracy: 0.6179 - val_loss: 29463.9121 - val_accuracy: 0.5694\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f73553cbbe0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, epochs=300, validation_data=val_ds, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "08a2e3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 45ms/step - loss: 27815.0352 - accuracy: 0.4977\n",
      "Accuracy 0.4976744055747986\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print(\"Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f98ec6b",
   "metadata": {},
   "source": [
    "Optional: Save model for later reuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b58dd68b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-11 10:48:07.300508: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Function `_wrapped_model` contains input name(s) start_coords.x, start_coords.y, start_coords.z, 4.already_seen, bowl_1.already_seen, k.already_seen, dish_3.already_seen, c.already_seen, 2.already_seen, d.already_seen, dish_2.already_seen, t.already_seen, 8.already_seen, r.already_seen, i.already_seen, glass_3.already_seen, g.already_seen, 9.already_seen, n.already_seen, silverware_2.already_seen, 7.already_seen, w.already_seen, z.already_seen, silverware_3.already_seen, bowl_3.already_seen, x.already_seen, o.already_seen, a.already_seen, q.already_seen, silverware_1.already_seen, j.already_seen, b.already_seen, plate_1.already_seen, 1.already_seen, v.already_seen, 0.already_seen, 3.already_seen, 5.already_seen, y.already_seen, s.already_seen, p.already_seen, h.already_seen, e.already_seen, m.already_seen, f.already_seen, u.already_seen, 6.already_seen, coordinates_p.x, coordinates_p.y, coordinates_p.z, p.containment, p.food_k, p.strong_k, p.mid_k, coordinates_o.x, coordinates_o.y, coordinates_o.z, o.containment, o.food_k, o.strong_k, o.mid_k, coordinates_c.x, coordinates_c.y, coordinates_c.z, c.containment, c.food_k, c.strong_k, c.mid_k, coordinates_g.x, coordinates_g.y, coordinates_g.z, g.containment, g.food_k, g.strong_k, g.mid_k, coordinates_k.x, coordinates_k.y, coordinates_k.z, k.containment, k.food_k, k.strong_k, k.mid_k, coordinates_r.x, coordinates_r.y, coordinates_r.z, r.containment, r.food_k, r.strong_k, r.mid_k, coordinates_w.x, coordinates_w.y, coordinates_w.z, w.containment, w.food_k, w.strong_k, w.mid_k, coordinates_f.x, coordinates_f.y, coordinates_f.z, f.containment, f.food_k, f.strong_k, f.mid_k, coordinates_s.x, coordinates_s.y, coordinates_s.z, s.containment, s.food_k, s.strong_k, s.mid_k, coordinates_t.x, coordinates_t.y, coordinates_t.z, t.containment, t.food_k, t.strong_k, t.mid_k, coordinates_e.x, coordinates_e.y, coordinates_e.z, e.containment, e.food_k, e.strong_k, e.mid_k, coordinates_n.x, coordinates_n.y, coordinates_n.z, n.containment, n.food_k, n.strong_k, n.mid_k, coordinates_z.x, coordinates_z.y, coordinates_z.z, z.containment, z.food_k, z.strong_k, z.mid_k, coordinates_m.x, coordinates_m.y, coordinates_m.z, m.containment, m.food_k, m.strong_k, m.mid_k, coordinates_x.x, coordinates_x.y, coordinates_x.z, x.containment, x.food_k, x.strong_k, x.mid_k, coordinates_i.x, coordinates_i.y, coordinates_i.z, i.containment, i.food_k, i.strong_k, i.mid_k, coordinates_h.x, coordinates_h.y, coordinates_h.z, h.containment, h.food_k, h.strong_k, h.mid_k, coordinates_b.x, coordinates_b.y, coordinates_b.z, b.containment, b.food_k, b.strong_k, b.mid_k, coordinates_a.x, coordinates_a.y, coordinates_a.z, a.containment, a.food_k, a.strong_k, a.mid_k, coordinates_d.x, coordinates_d.y, coordinates_d.z, d.containment, d.food_k, d.strong_k, d.mid_k, coordinates_u.x, coordinates_u.y, coordinates_u.z, u.containment, u.food_k, u.strong_k, u.mid_k, coordinates_q.x, coordinates_q.y, coordinates_q.z, q.containment, q.food_k, q.strong_k, q.mid_k, coordinates_v.x, coordinates_v.y, coordinates_v.z, v.containment, v.food_k, v.strong_k, v.mid_k, coordinates_y.x, coordinates_y.y, coordinates_y.z, y.containment, y.food_k, y.strong_k, y.mid_k, coordinates_0.x, coordinates_0.y, coordinates_0.z, 0.containment, 0.food_k, 0.strong_k, 0.mid_k, coordinates_silverware_3.x, coordinates_silverware_3.y, coordinates_silverware_3.z, silverware_3.containment, silverware_3.food_k, silverware_3.strong_k, silverware_3.mid_k, coordinates_2.x, coordinates_2.y, coordinates_2.z, 2.containment, 2.food_k, 2.strong_k, 2.mid_k, coordinates_3.x, coordinates_3.y, coordinates_3.z, 3.containment, 3.food_k, 3.strong_k, 3.mid_k, coordinates_4.x, coordinates_4.y, coordinates_4.z, 4.containment, 4.food_k, 4.strong_k, 4.mid_k, coordinates_5.x, coordinates_5.y, coordinates_5.z, 5.containment, 5.food_k, 5.strong_k, 5.mid_k, coordinates_1.x, coordinates_1.y, coordinates_1.z, 1.containment, 1.food_k, 1.strong_k, 1.mid_k, coordinates_plate_1.x, coordinates_plate_1.y, coordinates_plate_1.z, plate_1.containment, plate_1.food_k, plate_1.strong_k, plate_1.mid_k, coordinates_6.x, coordinates_6.y, coordinates_6.z, 6.containment, 6.food_k, 6.strong_k, 6.mid_k, coordinates_glass_3.x, coordinates_glass_3.y, coordinates_glass_3.z, glass_3.containment, glass_3.food_k, glass_3.strong_k, glass_3.mid_k, coordinates_7.x, coordinates_7.y, coordinates_7.z, 7.containment, 7.food_k, 7.strong_k, 7.mid_k, coordinates_8.x, coordinates_8.y, coordinates_8.z, 8.containment, 8.food_k, 8.strong_k, 8.mid_k, coordinates_silverware_2.x, coordinates_silverware_2.y, coordinates_silverware_2.z, silverware_2.containment, silverware_2.food_k, silverware_2.strong_k, silverware_2.mid_k, coordinates_silverware_1.x, coordinates_silverware_1.y, coordinates_silverware_1.z, silverware_1.containment, silverware_1.food_k, silverware_1.strong_k, silverware_1.mid_k, coordinates_bowl_1.x, coordinates_bowl_1.y, coordinates_bowl_1.z, bowl_1.containment, bowl_1.food_k, bowl_1.strong_k, bowl_1.mid_k, coordinates_j.x, coordinates_j.y, coordinates_j.z, j.containment, j.food_k, j.strong_k, j.mid_k, coordinates_dish_2.x, coordinates_dish_2.y, coordinates_dish_2.z, dish_2.containment, dish_2.food_k, dish_2.strong_k, dish_2.mid_k, coordinates_bowl_3.x, coordinates_bowl_3.y, coordinates_bowl_3.z, bowl_3.containment, bowl_3.food_k, bowl_3.strong_k, bowl_3.mid_k, coordinates_dish_3.x, coordinates_dish_3.y, coordinates_dish_3.z, dish_3.containment, dish_3.food_k, dish_3.strong_k, dish_3.mid_k, coordinates_9.x, coordinates_9.y, coordinates_9.z, 9.containment, 9.food_k, 9.strong_k, 9.mid_k with unsupported characters which will be renamed to start_coords_x, start_coords_y, start_coords_z, already_seen, bowl_1_already_seen, k_already_seen, dish_3_already_seen, c_already_seen, already_seen_0, d_already_seen, dish_2_already_seen, t_already_seen, already_seen_1, r_already_seen, i_already_seen, glass_3_already_seen, g_already_seen, already_seen_2, n_already_seen, silverware_2_already_seen, already_seen_3, w_already_seen, z_already_seen, silverware_3_already_seen, bowl_3_already_seen, x_already_seen, o_already_seen, a_already_seen, q_already_seen, silverware_1_already_seen, j_already_seen, b_already_seen, plate_1_already_seen, already_seen_4, v_already_seen, already_seen_5, already_seen_6, already_seen_7, y_already_seen, s_already_seen, p_already_seen, h_already_seen, e_already_seen, m_already_seen, f_already_seen, u_already_seen, already_seen_8, coordinates_p_x, coordinates_p_y, coordinates_p_z, p_containment, p_food_k, p_strong_k, p_mid_k, coordinates_o_x, coordinates_o_y, coordinates_o_z, o_containment, o_food_k, o_strong_k, o_mid_k, coordinates_c_x, coordinates_c_y, coordinates_c_z, c_containment, c_food_k, c_strong_k, c_mid_k, coordinates_g_x, coordinates_g_y, coordinates_g_z, g_containment, g_food_k, g_strong_k, g_mid_k, coordinates_k_x, coordinates_k_y, coordinates_k_z, k_containment, k_food_k, k_strong_k, k_mid_k, coordinates_r_x, coordinates_r_y, coordinates_r_z, r_containment, r_food_k, r_strong_k, r_mid_k, coordinates_w_x, coordinates_w_y, coordinates_w_z, w_containment, w_food_k, w_strong_k, w_mid_k, coordinates_f_x, coordinates_f_y, coordinates_f_z, f_containment, f_food_k, f_strong_k, f_mid_k, coordinates_s_x, coordinates_s_y, coordinates_s_z, s_containment, s_food_k, s_strong_k, s_mid_k, coordinates_t_x, coordinates_t_y, coordinates_t_z, t_containment, t_food_k, t_strong_k, t_mid_k, coordinates_e_x, coordinates_e_y, coordinates_e_z, e_containment, e_food_k, e_strong_k, e_mid_k, coordinates_n_x, coordinates_n_y, coordinates_n_z, n_containment, n_food_k, n_strong_k, n_mid_k, coordinates_z_x, coordinates_z_y, coordinates_z_z, z_containment, z_food_k, z_strong_k, z_mid_k, coordinates_m_x, coordinates_m_y, coordinates_m_z, m_containment, m_food_k, m_strong_k, m_mid_k, coordinates_x_x, coordinates_x_y, coordinates_x_z, x_containment, x_food_k, x_strong_k, x_mid_k, coordinates_i_x, coordinates_i_y, coordinates_i_z, i_containment, i_food_k, i_strong_k, i_mid_k, coordinates_h_x, coordinates_h_y, coordinates_h_z, h_containment, h_food_k, h_strong_k, h_mid_k, coordinates_b_x, coordinates_b_y, coordinates_b_z, b_containment, b_food_k, b_strong_k, b_mid_k, coordinates_a_x, coordinates_a_y, coordinates_a_z, a_containment, a_food_k, a_strong_k, a_mid_k, coordinates_d_x, coordinates_d_y, coordinates_d_z, d_containment, d_food_k, d_strong_k, d_mid_k, coordinates_u_x, coordinates_u_y, coordinates_u_z, u_containment, u_food_k, u_strong_k, u_mid_k, coordinates_q_x, coordinates_q_y, coordinates_q_z, q_containment, q_food_k, q_strong_k, q_mid_k, coordinates_v_x, coordinates_v_y, coordinates_v_z, v_containment, v_food_k, v_strong_k, v_mid_k, coordinates_y_x, coordinates_y_y, coordinates_y_z, y_containment, y_food_k, y_strong_k, y_mid_k, coordinates_0_x, coordinates_0_y, coordinates_0_z, containment, food_k, strong_k, mid_k, coordinates_silverware_3_x, coordinates_silverware_3_y, coordinates_silverware_3_z, silverware_3_containment, silverware_3_food_k, silverware_3_strong_k, silverware_3_mid_k, coordinates_2_x, coordinates_2_y, coordinates_2_z, containment_0, food_k_0, strong_k_0, mid_k_0, coordinates_3_x, coordinates_3_y, coordinates_3_z, containment_1, food_k_1, strong_k_1, mid_k_1, coordinates_4_x, coordinates_4_y, coordinates_4_z, containment_2, food_k_2, strong_k_2, mid_k_2, coordinates_5_x, coordinates_5_y, coordinates_5_z, containment_3, food_k_3, strong_k_3, mid_k_3, coordinates_1_x, coordinates_1_y, coordinates_1_z, containment_4, food_k_4, strong_k_4, mid_k_4, coordinates_plate_1_x, coordinates_plate_1_y, coordinates_plate_1_z, plate_1_containment, plate_1_food_k, plate_1_strong_k, plate_1_mid_k, coordinates_6_x, coordinates_6_y, coordinates_6_z, containment_5, food_k_5, strong_k_5, mid_k_5, coordinates_glass_3_x, coordinates_glass_3_y, coordinates_glass_3_z, glass_3_containment, glass_3_food_k, glass_3_strong_k, glass_3_mid_k, coordinates_7_x, coordinates_7_y, coordinates_7_z, containment_6, food_k_6, strong_k_6, mid_k_6, coordinates_8_x, coordinates_8_y, coordinates_8_z, containment_7, food_k_7, strong_k_7, mid_k_7, coordinates_silverware_2_x, coordinates_silverware_2_y, coordinates_silverware_2_z, silverware_2_containment, silverware_2_food_k, silverware_2_strong_k, silverware_2_mid_k, coordinates_silverware_1_x, coordinates_silverware_1_y, coordinates_silverware_1_z, silverware_1_containment, silverware_1_food_k, silverware_1_strong_k, silverware_1_mid_k, coordinates_bowl_1_x, coordinates_bowl_1_y, coordinates_bowl_1_z, bowl_1_containment, bowl_1_food_k, bowl_1_strong_k, bowl_1_mid_k, coordinates_j_x, coordinates_j_y, coordinates_j_z, j_containment, j_food_k, j_strong_k, j_mid_k, coordinates_dish_2_x, coordinates_dish_2_y, coordinates_dish_2_z, dish_2_containment, dish_2_food_k, dish_2_strong_k, dish_2_mid_k, coordinates_bowl_3_x, coordinates_bowl_3_y, coordinates_bowl_3_z, bowl_3_containment, bowl_3_food_k, bowl_3_strong_k, bowl_3_mid_k, coordinates_dish_3_x, coordinates_dish_3_y, coordinates_dish_3_z, dish_3_containment, dish_3_food_k, dish_3_strong_k, dish_3_mid_k, coordinates_9_x, coordinates_9_y, coordinates_9_z, containment_8, food_k_8, strong_k_8, mid_k_8 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/next_obj_classifier_tablesetting_2022-10-11/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/next_obj_classifier_tablesetting_2022-10-11/assets\n"
     ]
    }
   ],
   "source": [
    "# model.save('models/next_obj_classifier_tablesetting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e33c5a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reloaded_model = tf.keras.models.load_model('models/next_obj_classifier_tablesetting')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b090d1f",
   "metadata": {},
   "source": [
    "### Test model prediction for one sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b50493d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df.loc[0].drop('target').to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "63d9fe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dict = {name: tf.convert_to_tensor([value]) for name, value in sample.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2e68164e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(input_dict)\n",
    "prediction = tf.nn.sigmoid(prediction[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d55466",
   "metadata": {},
   "source": [
    "Get label for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "27161320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'p'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_label = labels[np.argmax(prediction)]\n",
    "pred_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a468d4d7",
   "metadata": {},
   "source": [
    "## 5. Run prediction for each sequence using prequential approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ae9f505d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prequential_error(dataframe, model, labels, nr_of_sequences):\n",
    "    errors = [[] for seq in range(0, nr_of_sequences + 1)]\n",
    "    predictions = [[] for seq in range(0, nr_of_sequences + 1)]\n",
    "    start_token_count = 0\n",
    "    sequence_nr = 0\n",
    "    \n",
    "    for row in trange(dataframe.index[0], dataframe.index[-1]): \n",
    "        observed_target = dataframe.loc[row, 'target']\n",
    "        sample = dataframe.loc[row].drop('target').to_dict()\n",
    "        input_dict = {name: tf.convert_to_tensor([value]) for name, value in \n",
    "                          sample.items()}\n",
    "        predicted_target = model.predict(input_dict)\n",
    "        predicted_target = tf.nn.sigmoid(predicted_target[0])\n",
    "            \n",
    "        pred_label = labels[np.argmax(predicted_target)]\n",
    "        error = 1 - damerauLevenshtein(pred_label, observed_target)\n",
    "        errors[sequence_nr].append(error)\n",
    "        predictions[sequence_nr].append(pred_label)\n",
    "        \n",
    "        if row != 0 and dataframe.loc[row, 'input'] == '<start>':\n",
    "            start_token_count += 1\n",
    "        \n",
    "        if start_token_count > 0:\n",
    "            sequence_nr += 1\n",
    "            start_token_count = 0\n",
    "            \n",
    "    return errors, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c576f3",
   "metadata": {},
   "source": [
    "Define number of sequences for which prediction is run (cooking data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "02a4e023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nr_of_sequences_preds = len(df[2075:][df[2075:]['input'] == '<start>'])\n",
    "nr_of_sequences_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dbf0e0",
   "metadata": {},
   "source": [
    "Run prediction, sum up errors and get median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d7ae2385",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████| 127/127 [01:24<00:00,  1.50it/s]\n"
     ]
    }
   ],
   "source": [
    "errors, predictions = get_prequential_error(df[2075:], model, labels, nr_of_sequences_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c3eacff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "summed_error = [sum(error) for error in errors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "28e4a79e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(summed_error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.7",
   "language": "python",
   "name": "tf2.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
