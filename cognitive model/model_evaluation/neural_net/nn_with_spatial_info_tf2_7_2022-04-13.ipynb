{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8da2a4b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "#from fastDamerauLevenshtein import damerauLevenshtein\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36834bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "49e7518e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/single_step_df_ints_2022-04-13_categorized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "99988333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "      <th>start_coords.x</th>\n",
       "      <th>start_coords.y</th>\n",
       "      <th>start_coords.z</th>\n",
       "      <th>tray.already_seen</th>\n",
       "      <th>bowl.already_seen</th>\n",
       "      <th>wineglass.already_seen</th>\n",
       "      <th>silverware.already_seen</th>\n",
       "      <th>spoon.already_seen</th>\n",
       "      <th>...</th>\n",
       "      <th>cookware.food_k</th>\n",
       "      <th>cookware.mid_k</th>\n",
       "      <th>cookware.strong_k</th>\n",
       "      <th>cookware.x</th>\n",
       "      <th>cookware.y</th>\n",
       "      <th>cookware.z</th>\n",
       "      <th>cookware.already_seen</th>\n",
       "      <th>bowl.x</th>\n",
       "      <th>bowl.y</th>\n",
       "      <th>bowl.z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;start&gt;</td>\n",
       "      <td>plate</td>\n",
       "      <td>-0.451354</td>\n",
       "      <td>-0.413918</td>\n",
       "      <td>0.156247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>plate</td>\n",
       "      <td>plate_small</td>\n",
       "      <td>0.513000</td>\n",
       "      <td>-0.531000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>plate_small</td>\n",
       "      <td>cup</td>\n",
       "      <td>0.513000</td>\n",
       "      <td>-0.531000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cup</td>\n",
       "      <td>glass</td>\n",
       "      <td>0.513000</td>\n",
       "      <td>-0.531000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>glass</td>\n",
       "      <td>knife</td>\n",
       "      <td>0.513000</td>\n",
       "      <td>-0.531000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2096</th>\n",
       "      <td>&lt;start&gt;</td>\n",
       "      <td>food</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097</th>\n",
       "      <td>pineapple</td>\n",
       "      <td>cutting_board</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>cutting_board</td>\n",
       "      <td>knife</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099</th>\n",
       "      <td>knife</td>\n",
       "      <td>container</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2100</th>\n",
       "      <td>plastic_box</td>\n",
       "      <td>seasoning</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2101 rows × 190 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              input         target  start_coords.x  start_coords.y  \\\n",
       "0           <start>          plate       -0.451354       -0.413918   \n",
       "1             plate    plate_small        0.513000       -0.531000   \n",
       "2       plate_small            cup        0.513000       -0.531000   \n",
       "3               cup          glass        0.513000       -0.531000   \n",
       "4             glass          knife        0.513000       -0.531000   \n",
       "...             ...            ...             ...             ...   \n",
       "2096        <start>           food        1.000000        0.000000   \n",
       "2097      pineapple  cutting_board        0.000000        1.500000   \n",
       "2098  cutting_board          knife        0.000000        1.500000   \n",
       "2099          knife      container        0.000000        1.500000   \n",
       "2100    plastic_box      seasoning        0.000000        1.500000   \n",
       "\n",
       "      start_coords.z  tray.already_seen  bowl.already_seen  \\\n",
       "0           0.156247                0.0                0.0   \n",
       "1           0.740000                0.0                0.0   \n",
       "2           0.740000                0.0                0.0   \n",
       "3           0.740000                0.0                0.0   \n",
       "4           0.740000                0.0                0.0   \n",
       "...              ...                ...                ...   \n",
       "2096        2.000000                0.0                0.0   \n",
       "2097        2.000000                0.0                0.0   \n",
       "2098        2.000000                0.0                0.0   \n",
       "2099        2.000000                0.0                0.0   \n",
       "2100        2.000000                0.0                0.0   \n",
       "\n",
       "      wineglass.already_seen  silverware.already_seen  spoon.already_seen  \\\n",
       "0                        0.0                      0.0                 0.0   \n",
       "1                        0.0                      0.0                 0.0   \n",
       "2                        0.0                      0.0                 0.0   \n",
       "3                        0.0                      0.0                 0.0   \n",
       "4                        0.0                      0.0                 0.0   \n",
       "...                      ...                      ...                 ...   \n",
       "2096                     0.0                      0.0                 0.0   \n",
       "2097                     0.0                      0.0                 0.0   \n",
       "2098                     0.0                      0.0                 0.0   \n",
       "2099                     0.0                      0.0                 0.0   \n",
       "2100                     0.0                      0.0                 0.0   \n",
       "\n",
       "      ...  cookware.food_k  cookware.mid_k  cookware.strong_k  cookware.x  \\\n",
       "0     ...              NaN             NaN                NaN         NaN   \n",
       "1     ...              NaN             NaN                NaN         NaN   \n",
       "2     ...              NaN             NaN                NaN         NaN   \n",
       "3     ...              NaN             NaN                NaN         NaN   \n",
       "4     ...              NaN             NaN                NaN         NaN   \n",
       "...   ...              ...             ...                ...         ...   \n",
       "2096  ...              NaN             NaN                NaN         NaN   \n",
       "2097  ...              NaN             NaN                NaN         NaN   \n",
       "2098  ...              NaN             NaN                NaN         NaN   \n",
       "2099  ...              NaN             NaN                NaN         NaN   \n",
       "2100  ...              NaN             NaN                NaN         NaN   \n",
       "\n",
       "      cookware.y  cookware.z  cookware.already_seen  bowl.x  bowl.y  bowl.z  \n",
       "0            NaN         NaN                    NaN     NaN     NaN     NaN  \n",
       "1            NaN         NaN                    NaN     NaN     NaN     NaN  \n",
       "2            NaN         NaN                    NaN     NaN     NaN     NaN  \n",
       "3            NaN         NaN                    NaN     NaN     NaN     NaN  \n",
       "4            NaN         NaN                    NaN     NaN     NaN     NaN  \n",
       "...          ...         ...                    ...     ...     ...     ...  \n",
       "2096         NaN         NaN                    NaN     NaN     NaN     NaN  \n",
       "2097         NaN         NaN                    NaN     NaN     NaN     NaN  \n",
       "2098         NaN         NaN                    NaN     NaN     NaN     NaN  \n",
       "2099         NaN         NaN                    NaN     NaN     NaN     NaN  \n",
       "2100         NaN         NaN                    NaN     NaN     NaN     NaN  \n",
       "\n",
       "[2101 rows x 190 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "52fca39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "float_cols = df.select_dtypes(include=['float64']).columns\n",
    "df.loc[:, float_cols] = df.loc[:, float_cols].fillna(-99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f8e9acc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "knife            279\n",
       "plate            249\n",
       "fork             172\n",
       "glass            172\n",
       "food             169\n",
       "cup              152\n",
       "spoon            146\n",
       "bowl             114\n",
       "cutting_board    107\n",
       "wineglass         74\n",
       "bottle            74\n",
       "plate_small       73\n",
       "utensil           56\n",
       "spoon_small       47\n",
       "seasoning         43\n",
       "drink             36\n",
       "cookware          30\n",
       "fork_small        22\n",
       "tray              22\n",
       "silverware        21\n",
       "teaspoon          13\n",
       "placemat          13\n",
       "napkin             9\n",
       "container          7\n",
       "egg_cup            1\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].unique()\n",
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "af2bd3d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1972"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_drop = df['target'].loc[df['target'] == 'egg_cup'].index[0]\n",
    "index_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d3401a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_of_sequences = len(df[df['input'] == '<start>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "16af1823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove row with target that only occurs once\n",
    "\n",
    "df_new = df.drop(index=index_to_drop, axis=0)\n",
    "df_new.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5491f1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate stratified split\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=10, test_size=0.3, random_state=42)\n",
    "\n",
    "for train_index, test_index in split.split(df_new, df_new['target']):\n",
    "    strat_train = df_new.loc[train_index]\n",
    "    strat_test_val = df_new.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b13b3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "11eba3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split test_val into test and val\n",
    "\n",
    "split_test_val = len(strat_test_val)//2\n",
    "\n",
    "strat_test = strat_test_val[:split_test_val]\n",
    "strat_val = strat_test_val[split_test_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ead4a95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate list of labels to pass to MultiLabelBinarizer so there's the same number of\n",
    "# classes for all datasets\n",
    "\n",
    "labels = df_new['target'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce71230e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2e8da447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataframe, labels, shuffle=True, batch_size=32):\n",
    "    df = dataframe.copy()\n",
    "    labels_ds = df.pop('target')\n",
    "    encoder = MultiLabelBinarizer(classes=labels)\n",
    "    encoded_labels = encoder.fit_transform(labels_ds)\n",
    "    \n",
    "    df = {key: value[:, tf.newaxis] for key, value in df.items()}\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(df), encoded_labels))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=len(dataframe))\n",
    "    \n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(batch_size)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9e6e6001",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "416e6d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zauri/files/miniconda3/envs/tf2.7/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:875: UserWarning: unknown class(es) ['_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'i', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'y'] will be ignored\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_29915/1510453973.py:7: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  df = {key: value[:, tf.newaxis] for key, value in df.items()}\n"
     ]
    }
   ],
   "source": [
    "train_ds = create_dataset(strat_train, labels, batch_size=batch_size)\n",
    "val_ds = create_dataset(strat_val, labels, shuffle=False, batch_size=batch_size)\n",
    "test_ds = create_dataset(strat_test, labels, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb42795",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "06f4db47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalization_layer(name, dataset):\n",
    "  # Create a Normalization layer for the feature.\n",
    "    normalizer = layers.Normalization(axis=None)\n",
    "\n",
    "  # Prepare a Dataset that only yields the feature.\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "\n",
    "  # Learn the statistics of the data.\n",
    "    normalizer.adapt(feature_ds)\n",
    "    \n",
    "    return normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "597f7ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_encoding_layer(name, dataset, dtype, max_tokens=None):\n",
    "    if dtype == 'string':\n",
    "        index = layers.StringLookup(max_tokens=max_tokens)\n",
    "    else:\n",
    "        index = layers.IntegerLookup(max_tokens=max_tokens)\n",
    "        \n",
    "    # prepare tf.data.Dataset that only yields the feature    \n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    \n",
    "    # learn set of possible values and assign fixed int index\n",
    "    index.adapt(feature_ds)\n",
    "    \n",
    "    # encode int indices\n",
    "    encoder = layers.CategoryEncoding(num_tokens=index.vocabulary_size())\n",
    "    \n",
    "    # apply multi-hot encoding to indices\n",
    "    # lambda function captures the layer to include them in Keras functional models later\n",
    "    return lambda feature: encoder(index(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9ce78468",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_data(dataframe):\n",
    "    all_inputs = []\n",
    "    encoded_features = []\n",
    "    \n",
    "    for header in dataframe.columns:\n",
    "        # numerical features\n",
    "        if 'coord' in header or 'already' in header:\n",
    "            numeric_col = tf.keras.Input(shape=(1,), name=header)\n",
    "            normalization_layer = get_normalization_layer(header, train_ds)\n",
    "            encoded_numeric_col = normalization_layer(numeric_col)\n",
    "            all_inputs.append(numeric_col)\n",
    "            encoded_features.append(encoded_numeric_col)\n",
    "        \n",
    "        # categorical features\n",
    "        elif 'containment' in header or 'food' in header or 'mid' in header or \\\n",
    "        'strong' in header:\n",
    "            categorical_col = tf.keras.Input(shape=(1,), name=header, dtype='int64')\n",
    "            encoding_layer = get_category_encoding_layer(name=header,\n",
    "                                                        dataset=train_ds,\n",
    "                                                        dtype='int64')\n",
    "            encoded_categorical_col = encoding_layer(categorical_col)\n",
    "            all_inputs.append(categorical_col)\n",
    "            encoded_features.append(encoded_categorical_col)\n",
    "            \n",
    "        elif header == 'input':\n",
    "            categorical_col = tf.keras.Input(shape=(1,), name='input', dtype='string')\n",
    "            encoding_layer = get_category_encoding_layer(name='input',\n",
    "                                                        dataset=train_ds,\n",
    "                                                        dtype='string')\n",
    "            encoded_categorical_col = encoding_layer(categorical_col)\n",
    "            all_inputs.append(categorical_col)\n",
    "            encoded_features.append(encoded_categorical_col)\n",
    "            \n",
    "    return all_inputs, encoded_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8d333498",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_inputs, encoded_features = create_input_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2de5cf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5caa2ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use model from tutorial with dense layers\n",
    "\n",
    "all_features = tf.keras.layers.concatenate(encoded_features)\n",
    "x = tf.keras.layers.Dense(512, activation=\"relu\")(all_features)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(256, activation=\"relu\")(all_features)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "output = tf.keras.layers.Dense(24)(x)\n",
    "\n",
    "model = tf.keras.Model(all_inputs, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c1736d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5f1f8941",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.keras.utils.plot_model(model, show_shapes=True, rankdir='LR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9dee9ed0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 [==============================] - 8s 263ms/step - loss: 0.0000e+00 - accuracy: 0.0122 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.0000e+00 - accuracy: 0.0156 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.0000e+00 - accuracy: 0.0190 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 0.0000e+00 - accuracy: 0.0347 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.0000e+00 - accuracy: 0.0259 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 0.0000e+00 - accuracy: 0.0306 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa98d49bb50>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, epochs=100, validation_data=val_ds, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "08a2e3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
      "Accuracy 0.0\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print(\"Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b58dd68b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-23 12:41:32.131340: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Function `_wrapped_model` contains input name(s) start_coords.x, start_coords.y, start_coords.z, l.already_seen, d.already_seen, g.already_seen, f.already_seen, r.already_seen, z.already_seen, c.already_seen, w.already_seen, k.already_seen, p.already_seen, q.already_seen, t.already_seen, h.already_seen, x.already_seen, s.already_seen, e.already_seen, m.already_seen, b.already_seen, n.already_seen, o.already_seen, a.already_seen, coordinates_p.x, coordinates_p.y, coordinates_p.z, p.containment, p.food_k, p.strong_k, p.mid_k, coordinates_o.x, coordinates_o.y, coordinates_o.z, o.containment, o.food_k, o.strong_k, o.mid_k, coordinates_c.x, coordinates_c.y, coordinates_c.z, c.containment, c.food_k, c.strong_k, c.mid_k, coordinates_g.x, coordinates_g.y, coordinates_g.z, g.containment, g.food_k, g.strong_k, g.mid_k, coordinates_k.x, coordinates_k.y, coordinates_k.z, k.containment, k.food_k, k.strong_k, k.mid_k, coordinates_r.x, coordinates_r.y, coordinates_r.z, r.containment, r.food_k, r.strong_k, r.mid_k, coordinates_w.x, coordinates_w.y, coordinates_w.z, w.containment, w.food_k, w.strong_k, w.mid_k, coordinates_f.x, coordinates_f.y, coordinates_f.z, f.containment, f.food_k, f.strong_k, f.mid_k, coordinates_s.x, coordinates_s.y, coordinates_s.z, s.containment, s.food_k, s.strong_k, s.mid_k, coordinates_t.x, coordinates_t.y, coordinates_t.z, t.containment, t.food_k, t.strong_k, t.mid_k, coordinates_e.x, coordinates_e.y, coordinates_e.z, e.containment, e.food_k, e.strong_k, e.mid_k, coordinates_n.x, coordinates_n.y, coordinates_n.z, n.containment, n.food_k, n.strong_k, n.mid_k, coordinates_z.x, coordinates_z.y, coordinates_z.z, z.containment, z.food_k, z.strong_k, z.mid_k, coordinates_m.x, coordinates_m.y, coordinates_m.z, m.containment, m.food_k, m.strong_k, m.mid_k, coordinates_x.x, coordinates_x.y, coordinates_x.z, x.containment, x.food_k, x.strong_k, x.mid_k, coordinates_b.x, coordinates_b.y, coordinates_b.z, b.containment, b.food_k, b.strong_k, b.mid_k, coordinates_d.x, coordinates_d.y, coordinates_d.z, d.containment, d.food_k, d.strong_k, d.mid_k, coordinates_l.x, coordinates_l.y, coordinates_l.z, l.containment, l.food_k, l.strong_k, l.mid_k, coordinates_a.x, coordinates_a.y, coordinates_a.z, a.containment, a.food_k, a.strong_k, a.mid_k, coordinates_h.x, coordinates_h.y, coordinates_h.z, h.containment, h.food_k, h.strong_k, h.mid_k, coordinates_q.x, coordinates_q.y, coordinates_q.z, q.containment, q.food_k, q.strong_k, q.mid_k with unsupported characters which will be renamed to start_coords_x, start_coords_y, start_coords_z, l_already_seen, d_already_seen, g_already_seen, f_already_seen, r_already_seen, z_already_seen, c_already_seen, w_already_seen, k_already_seen, p_already_seen, q_already_seen, t_already_seen, h_already_seen, x_already_seen, s_already_seen, e_already_seen, m_already_seen, b_already_seen, n_already_seen, o_already_seen, a_already_seen, coordinates_p_x, coordinates_p_y, coordinates_p_z, p_containment, p_food_k, p_strong_k, p_mid_k, coordinates_o_x, coordinates_o_y, coordinates_o_z, o_containment, o_food_k, o_strong_k, o_mid_k, coordinates_c_x, coordinates_c_y, coordinates_c_z, c_containment, c_food_k, c_strong_k, c_mid_k, coordinates_g_x, coordinates_g_y, coordinates_g_z, g_containment, g_food_k, g_strong_k, g_mid_k, coordinates_k_x, coordinates_k_y, coordinates_k_z, k_containment, k_food_k, k_strong_k, k_mid_k, coordinates_r_x, coordinates_r_y, coordinates_r_z, r_containment, r_food_k, r_strong_k, r_mid_k, coordinates_w_x, coordinates_w_y, coordinates_w_z, w_containment, w_food_k, w_strong_k, w_mid_k, coordinates_f_x, coordinates_f_y, coordinates_f_z, f_containment, f_food_k, f_strong_k, f_mid_k, coordinates_s_x, coordinates_s_y, coordinates_s_z, s_containment, s_food_k, s_strong_k, s_mid_k, coordinates_t_x, coordinates_t_y, coordinates_t_z, t_containment, t_food_k, t_strong_k, t_mid_k, coordinates_e_x, coordinates_e_y, coordinates_e_z, e_containment, e_food_k, e_strong_k, e_mid_k, coordinates_n_x, coordinates_n_y, coordinates_n_z, n_containment, n_food_k, n_strong_k, n_mid_k, coordinates_z_x, coordinates_z_y, coordinates_z_z, z_containment, z_food_k, z_strong_k, z_mid_k, coordinates_m_x, coordinates_m_y, coordinates_m_z, m_containment, m_food_k, m_strong_k, m_mid_k, coordinates_x_x, coordinates_x_y, coordinates_x_z, x_containment, x_food_k, x_strong_k, x_mid_k, coordinates_b_x, coordinates_b_y, coordinates_b_z, b_containment, b_food_k, b_strong_k, b_mid_k, coordinates_d_x, coordinates_d_y, coordinates_d_z, d_containment, d_food_k, d_strong_k, d_mid_k, coordinates_l_x, coordinates_l_y, coordinates_l_z, l_containment, l_food_k, l_strong_k, l_mid_k, coordinates_a_x, coordinates_a_y, coordinates_a_z, a_containment, a_food_k, a_strong_k, a_mid_k, coordinates_h_x, coordinates_h_y, coordinates_h_z, h_containment, h_food_k, h_strong_k, h_mid_k, coordinates_q_x, coordinates_q_y, coordinates_q_z, q_containment, q_food_k, q_strong_k, q_mid_k in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/next_obj_classifier_2022-03-23/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/next_obj_classifier_2022-03-23/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('models/next_obj_classifier_2022-03-23')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e33c5a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "reloaded_model = tf.keras.models.load_model('models/next_obj_classifier_2022-03-23')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a6bfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test prediction for one sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b50493d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df.loc[0].drop('target').to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "63d9fe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dict = {name: tf.convert_to_tensor([value]) for name, value in sample.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2e68164e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = reloaded_model.predict(input_dict)\n",
    "prediction = tf.nn.sigmoid(prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad905aed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "27161320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'p'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get label for prediction\n",
    "\n",
    "pred_label = labels[np.argmax(prediction)]\n",
    "pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ae9f505d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prequential_error(dataframe, model, labels, nr_of_sequences):\n",
    "    errors = [[] for seq in range(0, nr_of_sequences + 1)]\n",
    "    start_token_count = 0\n",
    "    sequence_nr = 0\n",
    "    \n",
    "    for row in range(0, len(dataframe)): \n",
    "        observed_target = dataframe.loc[row, 'target']\n",
    "        sample = dataframe.loc[row].drop('target').to_dict()\n",
    "        input_dict = {name: tf.convert_to_tensor([value]) for name, value in \n",
    "                          sample.items()}\n",
    "        predicted_target = model.predict(input_dict)\n",
    "        predicted_target = tf.nn.sigmoid(predicted_target[0])\n",
    "            \n",
    "        pred_label = labels[np.argmax(predicted_target)]\n",
    "        error = 1 - damerauLevenshtein(pred_label, observed_target)\n",
    "        errors[sequence_nr].append(error)\n",
    "        \n",
    "        if row != 0 and dataframe.loc[row, 'input'] == '<start>':\n",
    "            start_token_count += 1\n",
    "        \n",
    "        if start_token_count > 0:\n",
    "            sequence_nr += 1\n",
    "            start_token_count = 0\n",
    "            \n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d7ae2385",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = get_prequential_error(df, model, labels, nr_of_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c3eacff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "summed_error = [sum(error) for error in errors[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "28e4a79e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(summed_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9edef143",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('results/nn_spatialinfo_prequential_summed_2022-03-23.txt', 'w') as file:\n",
    "#    file.write(str(summed_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cf9a2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.7",
   "language": "python",
   "name": "tf2.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
