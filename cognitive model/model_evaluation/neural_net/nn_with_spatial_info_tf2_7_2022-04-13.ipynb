{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8da2a4b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from fastDamerauLevenshtein import damerauLevenshtein\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36834bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49e7518e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/single_step_df_ints_2022-04-14_encoded.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99988333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "      <th>start_coords.x</th>\n",
       "      <th>start_coords.y</th>\n",
       "      <th>start_coords.z</th>\n",
       "      <th>h.already_seen</th>\n",
       "      <th>y.already_seen</th>\n",
       "      <th>e.already_seen</th>\n",
       "      <th>v.already_seen</th>\n",
       "      <th>o.already_seen</th>\n",
       "      <th>...</th>\n",
       "      <th>v.food_k</th>\n",
       "      <th>v.strong_k</th>\n",
       "      <th>v.mid_k</th>\n",
       "      <th>coordinates_y.x</th>\n",
       "      <th>coordinates_y.y</th>\n",
       "      <th>coordinates_y.z</th>\n",
       "      <th>y.containment</th>\n",
       "      <th>y.food_k</th>\n",
       "      <th>y.strong_k</th>\n",
       "      <th>y.mid_k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;start&gt;</td>\n",
       "      <td>p</td>\n",
       "      <td>-0.451354</td>\n",
       "      <td>-0.413918</td>\n",
       "      <td>0.156247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p</td>\n",
       "      <td>o</td>\n",
       "      <td>0.513000</td>\n",
       "      <td>-0.531000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>o</td>\n",
       "      <td>c</td>\n",
       "      <td>0.513000</td>\n",
       "      <td>-0.531000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c</td>\n",
       "      <td>g</td>\n",
       "      <td>0.513000</td>\n",
       "      <td>-0.531000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>g</td>\n",
       "      <td>k</td>\n",
       "      <td>0.513000</td>\n",
       "      <td>-0.531000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2096</th>\n",
       "      <td>&lt;start&gt;</td>\n",
       "      <td>d</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097</th>\n",
       "      <td>d</td>\n",
       "      <td>i</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>i</td>\n",
       "      <td>k</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099</th>\n",
       "      <td>k</td>\n",
       "      <td>x</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2100</th>\n",
       "      <td>x</td>\n",
       "      <td>q</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2101 rows Ã— 197 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        input target  start_coords.x  start_coords.y  start_coords.z  \\\n",
       "0     <start>      p       -0.451354       -0.413918        0.156247   \n",
       "1           p      o        0.513000       -0.531000        0.740000   \n",
       "2           o      c        0.513000       -0.531000        0.740000   \n",
       "3           c      g        0.513000       -0.531000        0.740000   \n",
       "4           g      k        0.513000       -0.531000        0.740000   \n",
       "...       ...    ...             ...             ...             ...   \n",
       "2096  <start>      d        1.000000        0.000000        2.000000   \n",
       "2097        d      i        0.000000        1.500000        2.000000   \n",
       "2098        i      k        0.000000        1.500000        2.000000   \n",
       "2099        k      x        0.000000        1.500000        2.000000   \n",
       "2100        x      q        0.000000        1.500000        2.000000   \n",
       "\n",
       "      h.already_seen  y.already_seen  e.already_seen  v.already_seen  \\\n",
       "0                0.0             0.0             0.0             0.0   \n",
       "1                0.0             0.0             0.0             0.0   \n",
       "2                0.0             0.0             0.0             0.0   \n",
       "3                0.0             0.0             0.0             0.0   \n",
       "4                0.0             0.0             0.0             0.0   \n",
       "...              ...             ...             ...             ...   \n",
       "2096             0.0             0.0             0.0             0.0   \n",
       "2097             0.0             0.0             0.0             0.0   \n",
       "2098             0.0             0.0             0.0             0.0   \n",
       "2099             0.0             0.0             0.0             0.0   \n",
       "2100             0.0             0.0             0.0             0.0   \n",
       "\n",
       "      o.already_seen  ...  v.food_k  v.strong_k  v.mid_k  coordinates_y.x  \\\n",
       "0                0.0  ...       NaN         NaN      NaN              NaN   \n",
       "1                0.0  ...       NaN         NaN      NaN              NaN   \n",
       "2                1.0  ...       NaN         NaN      NaN              NaN   \n",
       "3                1.0  ...       NaN         NaN      NaN              NaN   \n",
       "4                1.0  ...       NaN         NaN      NaN              NaN   \n",
       "...              ...  ...       ...         ...      ...              ...   \n",
       "2096             0.0  ...       NaN         NaN      NaN              NaN   \n",
       "2097             0.0  ...       NaN         NaN      NaN              NaN   \n",
       "2098             0.0  ...       NaN         NaN      NaN              NaN   \n",
       "2099             0.0  ...       NaN         NaN      NaN              NaN   \n",
       "2100             0.0  ...       NaN         NaN      NaN              NaN   \n",
       "\n",
       "      coordinates_y.y  coordinates_y.z  y.containment  y.food_k  y.strong_k  \\\n",
       "0                 NaN              NaN            NaN       NaN         NaN   \n",
       "1                 NaN              NaN            NaN       NaN         NaN   \n",
       "2                 NaN              NaN            NaN       NaN         NaN   \n",
       "3                 NaN              NaN            NaN       NaN         NaN   \n",
       "4                 NaN              NaN            NaN       NaN         NaN   \n",
       "...               ...              ...            ...       ...         ...   \n",
       "2096              NaN              NaN            NaN       NaN         NaN   \n",
       "2097              NaN              NaN            NaN       NaN         NaN   \n",
       "2098              NaN              NaN            NaN       NaN         NaN   \n",
       "2099              NaN              NaN            NaN       NaN         NaN   \n",
       "2100              NaN              NaN            NaN       NaN         NaN   \n",
       "\n",
       "      y.mid_k  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  \n",
       "...       ...  \n",
       "2096      NaN  \n",
       "2097      NaN  \n",
       "2098      NaN  \n",
       "2099      NaN  \n",
       "2100      NaN  \n",
       "\n",
       "[2101 rows x 197 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52fca39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "float_cols = df.select_dtypes(include=['float64']).columns\n",
    "df.loc[:, float_cols] = df.loc[:, float_cols].fillna(-99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8e9acc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "k    279\n",
       "p    249\n",
       "f    172\n",
       "g    172\n",
       "d    169\n",
       "c    152\n",
       "s    146\n",
       "b    114\n",
       "i    107\n",
       "w     74\n",
       "a     74\n",
       "o     73\n",
       "r     60\n",
       "u     56\n",
       "q     43\n",
       "h     36\n",
       "v     30\n",
       "e     22\n",
       "t     22\n",
       "z     21\n",
       "m     13\n",
       "n      9\n",
       "x      7\n",
       "y      1\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].unique()\n",
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af2bd3d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1972"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_drop = df['target'].loc[df['target'] == 'y'].index[0]\n",
    "index_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3401a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_of_sequences = len(df[df['input'] == '<start>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16af1823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove row with target that only occurs once\n",
    "\n",
    "df_new = df.drop(index=index_to_drop, axis=0)\n",
    "df_new.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5491f1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate stratified split\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=10, test_size=0.3, random_state=42)\n",
    "\n",
    "for train_index, test_index in split.split(df_new, df_new['target']):\n",
    "    strat_train = df_new.loc[train_index]\n",
    "    strat_test_val = df_new.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b13b3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11eba3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split test_val into test and val\n",
    "\n",
    "split_test_val = len(strat_test_val)//2\n",
    "\n",
    "strat_test = strat_test_val[:split_test_val]\n",
    "strat_val = strat_test_val[split_test_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ead4a95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate list of labels to pass to MultiLabelBinarizer so there's the same number of\n",
    "# classes for all datasets\n",
    "\n",
    "labels = df_new['target'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce71230e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e8da447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataframe, labels, shuffle=True, batch_size=32):\n",
    "    df = dataframe.copy()\n",
    "    labels_ds = df.pop('target')\n",
    "    encoder = MultiLabelBinarizer(classes=labels)\n",
    "    encoded_labels = encoder.fit_transform(labels_ds)\n",
    "    \n",
    "    df = {key: value[:, tf.newaxis] for key, value in df.items()}\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(df), encoded_labels))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=len(dataframe))\n",
    "    \n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(batch_size)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e6e6001",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "416e6d06",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40686/1510453973.py:7: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  df = {key: value[:, tf.newaxis] for key, value in df.items()}\n",
      "2022-04-14 11:44:05.331220: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-14 11:44:05.489532: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-14 11:44:05.489956: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-14 11:44:05.494338: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-14 11:44:05.495928: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-14 11:44:05.496298: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-14 11:44:05.496648: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-14 11:44:07.146586: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-14 11:44:07.146781: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-14 11:44:07.146943: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-14 11:44:07.147667: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2722 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 970, pci bus id: 0000:01:00.0, compute capability: 5.2\n"
     ]
    }
   ],
   "source": [
    "train_ds = create_dataset(strat_train, labels, batch_size=batch_size)\n",
    "val_ds = create_dataset(strat_val, labels, shuffle=False, batch_size=batch_size)\n",
    "test_ds = create_dataset(strat_test, labels, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb42795",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06f4db47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalization_layer(name, dataset):\n",
    "  # Create a Normalization layer for the feature.\n",
    "    normalizer = layers.Normalization(axis=None)\n",
    "\n",
    "  # Prepare a Dataset that only yields the feature.\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "\n",
    "  # Learn the statistics of the data.\n",
    "    normalizer.adapt(feature_ds)\n",
    "    \n",
    "    return normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "597f7ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_encoding_layer(name, dataset, dtype, max_tokens=None):\n",
    "    if dtype == 'string':\n",
    "        index = layers.StringLookup(max_tokens=max_tokens)\n",
    "    else:\n",
    "        index = layers.IntegerLookup(max_tokens=max_tokens)\n",
    "        \n",
    "    # prepare tf.data.Dataset that only yields the feature    \n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    \n",
    "    # learn set of possible values and assign fixed int index\n",
    "    index.adapt(feature_ds)\n",
    "    \n",
    "    # encode int indices\n",
    "    encoder = layers.CategoryEncoding(num_tokens=index.vocabulary_size())\n",
    "    \n",
    "    # apply multi-hot encoding to indices\n",
    "    # lambda function captures the layer to include them in Keras functional models later\n",
    "    return lambda feature: encoder(index(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ce78468",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_data(dataframe):\n",
    "    all_inputs = []\n",
    "    encoded_features = []\n",
    "    \n",
    "    for header in dataframe.columns:\n",
    "        # numerical features\n",
    "        if 'coord' in header or 'already' in header:\n",
    "            numeric_col = tf.keras.Input(shape=(1,), name=header)\n",
    "            normalization_layer = get_normalization_layer(header, train_ds)\n",
    "            encoded_numeric_col = normalization_layer(numeric_col)\n",
    "            all_inputs.append(numeric_col)\n",
    "            encoded_features.append(encoded_numeric_col)\n",
    "        \n",
    "        # categorical features\n",
    "        elif 'containment' in header or 'food' in header or 'mid' in header or \\\n",
    "        'strong' in header:\n",
    "            categorical_col = tf.keras.Input(shape=(1,), name=header, dtype='int64')\n",
    "            encoding_layer = get_category_encoding_layer(name=header,\n",
    "                                                        dataset=train_ds,\n",
    "                                                        dtype='int64')\n",
    "            encoded_categorical_col = encoding_layer(categorical_col)\n",
    "            all_inputs.append(categorical_col)\n",
    "            encoded_features.append(encoded_categorical_col)\n",
    "            \n",
    "        elif header == 'input':\n",
    "            categorical_col = tf.keras.Input(shape=(1,), name='input', dtype='string')\n",
    "            encoding_layer = get_category_encoding_layer(name='input',\n",
    "                                                        dataset=train_ds,\n",
    "                                                        dtype='string')\n",
    "            encoded_categorical_col = encoding_layer(categorical_col)\n",
    "            all_inputs.append(categorical_col)\n",
    "            encoded_features.append(encoded_categorical_col)\n",
    "            \n",
    "    return all_inputs, encoded_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d333498",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_inputs, encoded_features = create_input_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2de5cf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5caa2ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use model from tutorial with dense layers\n",
    "\n",
    "all_features = tf.keras.layers.concatenate(encoded_features)\n",
    "x = tf.keras.layers.Dense(512, activation=\"relu\")(all_features)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(256, activation=\"relu\")(all_features)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "output = tf.keras.layers.Dense(23)(x)\n",
    "\n",
    "model = tf.keras.Model(all_inputs, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1736d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5f1f8941",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.keras.utils.plot_model(model, show_shapes=True, rankdir='LR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9dee9ed0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 [==============================] - 9s 282ms/step - loss: 3.0198 - accuracy: 0.1306 - val_loss: 2.4622 - val_accuracy: 0.1683\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 2.4504 - accuracy: 0.1973 - val_loss: 2.2151 - val_accuracy: 0.2698\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 2.2396 - accuracy: 0.2327 - val_loss: 2.0839 - val_accuracy: 0.3238\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 2.0769 - accuracy: 0.2537 - val_loss: 2.0111 - val_accuracy: 0.3683\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 1.9968 - accuracy: 0.2898 - val_loss: 1.9494 - val_accuracy: 0.3873\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 1.9149 - accuracy: 0.3204 - val_loss: 1.8969 - val_accuracy: 0.4095\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 1.8318 - accuracy: 0.3544 - val_loss: 1.8398 - val_accuracy: 0.4317\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 1.7779 - accuracy: 0.3741 - val_loss: 1.7825 - val_accuracy: 0.4413\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 1s 49ms/step - loss: 1.7076 - accuracy: 0.4082 - val_loss: 1.7422 - val_accuracy: 0.4635\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 1.6942 - accuracy: 0.4197 - val_loss: 1.7085 - val_accuracy: 0.4508\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 1.6334 - accuracy: 0.4293 - val_loss: 1.6688 - val_accuracy: 0.4667\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 1.5631 - accuracy: 0.4476 - val_loss: 1.6372 - val_accuracy: 0.4698\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 1.5445 - accuracy: 0.4728 - val_loss: 1.6194 - val_accuracy: 0.4730\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 1.5111 - accuracy: 0.4796 - val_loss: 1.5886 - val_accuracy: 0.4889\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 1.4487 - accuracy: 0.5020 - val_loss: 1.5651 - val_accuracy: 0.4889\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 1.4562 - accuracy: 0.4844 - val_loss: 1.5471 - val_accuracy: 0.4921\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 1.4196 - accuracy: 0.5007 - val_loss: 1.5344 - val_accuracy: 0.5048\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 1.4337 - accuracy: 0.4912 - val_loss: 1.5188 - val_accuracy: 0.5206\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 1.3767 - accuracy: 0.5170 - val_loss: 1.5136 - val_accuracy: 0.5016\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 1.3752 - accuracy: 0.5224 - val_loss: 1.4994 - val_accuracy: 0.5111\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 1.3274 - accuracy: 0.5259 - val_loss: 1.4735 - val_accuracy: 0.5111\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 1.3340 - accuracy: 0.5347 - val_loss: 1.4645 - val_accuracy: 0.5492\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 1.2800 - accuracy: 0.5401 - val_loss: 1.4737 - val_accuracy: 0.5143\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 1.2600 - accuracy: 0.5694 - val_loss: 1.4444 - val_accuracy: 0.5270\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 1.2546 - accuracy: 0.5701 - val_loss: 1.4346 - val_accuracy: 0.5460\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 1.2571 - accuracy: 0.5728 - val_loss: 1.4433 - val_accuracy: 0.5587\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 1.2139 - accuracy: 0.5789 - val_loss: 1.4427 - val_accuracy: 0.5492\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 1.2165 - accuracy: 0.5728 - val_loss: 1.4455 - val_accuracy: 0.5429\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 1.2039 - accuracy: 0.5748 - val_loss: 1.4336 - val_accuracy: 0.5524\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 1.2105 - accuracy: 0.5857 - val_loss: 1.4372 - val_accuracy: 0.5460\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 1.1861 - accuracy: 0.5884 - val_loss: 1.4318 - val_accuracy: 0.5587\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 1.1899 - accuracy: 0.5837 - val_loss: 1.4201 - val_accuracy: 0.5238\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 1.1553 - accuracy: 0.5918 - val_loss: 1.4231 - val_accuracy: 0.5587\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 1.1663 - accuracy: 0.6000 - val_loss: 1.4092 - val_accuracy: 0.5524\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 1.1411 - accuracy: 0.6082 - val_loss: 1.4080 - val_accuracy: 0.5556\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 1.1406 - accuracy: 0.5986 - val_loss: 1.4089 - val_accuracy: 0.5397\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 1.1225 - accuracy: 0.5973 - val_loss: 1.4063 - val_accuracy: 0.5587\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 1.0926 - accuracy: 0.6163 - val_loss: 1.4032 - val_accuracy: 0.5492\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 1.0734 - accuracy: 0.6231 - val_loss: 1.4031 - val_accuracy: 0.5651\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 1.0840 - accuracy: 0.6048 - val_loss: 1.3976 - val_accuracy: 0.5587\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 1.0645 - accuracy: 0.6354 - val_loss: 1.4065 - val_accuracy: 0.5492\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 1s 49ms/step - loss: 1.0672 - accuracy: 0.6252 - val_loss: 1.4045 - val_accuracy: 0.5714\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 1.0594 - accuracy: 0.6286 - val_loss: 1.3983 - val_accuracy: 0.5460\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 1s 49ms/step - loss: 1.0742 - accuracy: 0.6190 - val_loss: 1.3953 - val_accuracy: 0.5556\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 1.0523 - accuracy: 0.6177 - val_loss: 1.3904 - val_accuracy: 0.5492\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 1.0463 - accuracy: 0.6286 - val_loss: 1.3967 - val_accuracy: 0.5556\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 1.0307 - accuracy: 0.6435 - val_loss: 1.3928 - val_accuracy: 0.5683\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 1.0396 - accuracy: 0.6279 - val_loss: 1.4026 - val_accuracy: 0.5524\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 1.0134 - accuracy: 0.6259 - val_loss: 1.4069 - val_accuracy: 0.5524\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 1.0237 - accuracy: 0.6374 - val_loss: 1.4021 - val_accuracy: 0.5460\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 1.0279 - accuracy: 0.6204 - val_loss: 1.3994 - val_accuracy: 0.5619\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 1.0360 - accuracy: 0.6313 - val_loss: 1.4058 - val_accuracy: 0.5397\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 1.0172 - accuracy: 0.6245 - val_loss: 1.3992 - val_accuracy: 0.5683\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 1s 49ms/step - loss: 1.0062 - accuracy: 0.6299 - val_loss: 1.3949 - val_accuracy: 0.5429\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 0.9953 - accuracy: 0.6435 - val_loss: 1.3846 - val_accuracy: 0.5429\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.9969 - accuracy: 0.6415 - val_loss: 1.3786 - val_accuracy: 0.5587\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 1s 49ms/step - loss: 0.9967 - accuracy: 0.6463 - val_loss: 1.3916 - val_accuracy: 0.5683\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 1s 49ms/step - loss: 1.0021 - accuracy: 0.6422 - val_loss: 1.4063 - val_accuracy: 0.5619\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 0.9829 - accuracy: 0.6408 - val_loss: 1.3954 - val_accuracy: 0.5460\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 0.9840 - accuracy: 0.6456 - val_loss: 1.4092 - val_accuracy: 0.5492\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 1s 49ms/step - loss: 1.0033 - accuracy: 0.6306 - val_loss: 1.4090 - val_accuracy: 0.5683\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 0.9836 - accuracy: 0.6320 - val_loss: 1.4180 - val_accuracy: 0.5460\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 0.9596 - accuracy: 0.6551 - val_loss: 1.4090 - val_accuracy: 0.5492\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 0.9640 - accuracy: 0.6619 - val_loss: 1.4113 - val_accuracy: 0.5619\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 1s 49ms/step - loss: 0.9438 - accuracy: 0.6646 - val_loss: 1.4057 - val_accuracy: 0.5651\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 0.9467 - accuracy: 0.6619 - val_loss: 1.4099 - val_accuracy: 0.5619\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.9120 - accuracy: 0.6721 - val_loss: 1.4066 - val_accuracy: 0.5492\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.9439 - accuracy: 0.6605 - val_loss: 1.4276 - val_accuracy: 0.5492\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 0.9590 - accuracy: 0.6592 - val_loss: 1.3982 - val_accuracy: 0.5397\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.9240 - accuracy: 0.6707 - val_loss: 1.4071 - val_accuracy: 0.5524\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.9443 - accuracy: 0.6646 - val_loss: 1.4163 - val_accuracy: 0.5587\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.9455 - accuracy: 0.6469 - val_loss: 1.4203 - val_accuracy: 0.5460\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f05214eff10>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, epochs=100, validation_data=val_ds, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08a2e3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 34ms/step - loss: 1.4500 - accuracy: 0.5270\n",
      "Accuracy 0.5269841551780701\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print(\"Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b58dd68b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-23 12:41:32.131340: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Function `_wrapped_model` contains input name(s) start_coords.x, start_coords.y, start_coords.z, l.already_seen, d.already_seen, g.already_seen, f.already_seen, r.already_seen, z.already_seen, c.already_seen, w.already_seen, k.already_seen, p.already_seen, q.already_seen, t.already_seen, h.already_seen, x.already_seen, s.already_seen, e.already_seen, m.already_seen, b.already_seen, n.already_seen, o.already_seen, a.already_seen, coordinates_p.x, coordinates_p.y, coordinates_p.z, p.containment, p.food_k, p.strong_k, p.mid_k, coordinates_o.x, coordinates_o.y, coordinates_o.z, o.containment, o.food_k, o.strong_k, o.mid_k, coordinates_c.x, coordinates_c.y, coordinates_c.z, c.containment, c.food_k, c.strong_k, c.mid_k, coordinates_g.x, coordinates_g.y, coordinates_g.z, g.containment, g.food_k, g.strong_k, g.mid_k, coordinates_k.x, coordinates_k.y, coordinates_k.z, k.containment, k.food_k, k.strong_k, k.mid_k, coordinates_r.x, coordinates_r.y, coordinates_r.z, r.containment, r.food_k, r.strong_k, r.mid_k, coordinates_w.x, coordinates_w.y, coordinates_w.z, w.containment, w.food_k, w.strong_k, w.mid_k, coordinates_f.x, coordinates_f.y, coordinates_f.z, f.containment, f.food_k, f.strong_k, f.mid_k, coordinates_s.x, coordinates_s.y, coordinates_s.z, s.containment, s.food_k, s.strong_k, s.mid_k, coordinates_t.x, coordinates_t.y, coordinates_t.z, t.containment, t.food_k, t.strong_k, t.mid_k, coordinates_e.x, coordinates_e.y, coordinates_e.z, e.containment, e.food_k, e.strong_k, e.mid_k, coordinates_n.x, coordinates_n.y, coordinates_n.z, n.containment, n.food_k, n.strong_k, n.mid_k, coordinates_z.x, coordinates_z.y, coordinates_z.z, z.containment, z.food_k, z.strong_k, z.mid_k, coordinates_m.x, coordinates_m.y, coordinates_m.z, m.containment, m.food_k, m.strong_k, m.mid_k, coordinates_x.x, coordinates_x.y, coordinates_x.z, x.containment, x.food_k, x.strong_k, x.mid_k, coordinates_b.x, coordinates_b.y, coordinates_b.z, b.containment, b.food_k, b.strong_k, b.mid_k, coordinates_d.x, coordinates_d.y, coordinates_d.z, d.containment, d.food_k, d.strong_k, d.mid_k, coordinates_l.x, coordinates_l.y, coordinates_l.z, l.containment, l.food_k, l.strong_k, l.mid_k, coordinates_a.x, coordinates_a.y, coordinates_a.z, a.containment, a.food_k, a.strong_k, a.mid_k, coordinates_h.x, coordinates_h.y, coordinates_h.z, h.containment, h.food_k, h.strong_k, h.mid_k, coordinates_q.x, coordinates_q.y, coordinates_q.z, q.containment, q.food_k, q.strong_k, q.mid_k with unsupported characters which will be renamed to start_coords_x, start_coords_y, start_coords_z, l_already_seen, d_already_seen, g_already_seen, f_already_seen, r_already_seen, z_already_seen, c_already_seen, w_already_seen, k_already_seen, p_already_seen, q_already_seen, t_already_seen, h_already_seen, x_already_seen, s_already_seen, e_already_seen, m_already_seen, b_already_seen, n_already_seen, o_already_seen, a_already_seen, coordinates_p_x, coordinates_p_y, coordinates_p_z, p_containment, p_food_k, p_strong_k, p_mid_k, coordinates_o_x, coordinates_o_y, coordinates_o_z, o_containment, o_food_k, o_strong_k, o_mid_k, coordinates_c_x, coordinates_c_y, coordinates_c_z, c_containment, c_food_k, c_strong_k, c_mid_k, coordinates_g_x, coordinates_g_y, coordinates_g_z, g_containment, g_food_k, g_strong_k, g_mid_k, coordinates_k_x, coordinates_k_y, coordinates_k_z, k_containment, k_food_k, k_strong_k, k_mid_k, coordinates_r_x, coordinates_r_y, coordinates_r_z, r_containment, r_food_k, r_strong_k, r_mid_k, coordinates_w_x, coordinates_w_y, coordinates_w_z, w_containment, w_food_k, w_strong_k, w_mid_k, coordinates_f_x, coordinates_f_y, coordinates_f_z, f_containment, f_food_k, f_strong_k, f_mid_k, coordinates_s_x, coordinates_s_y, coordinates_s_z, s_containment, s_food_k, s_strong_k, s_mid_k, coordinates_t_x, coordinates_t_y, coordinates_t_z, t_containment, t_food_k, t_strong_k, t_mid_k, coordinates_e_x, coordinates_e_y, coordinates_e_z, e_containment, e_food_k, e_strong_k, e_mid_k, coordinates_n_x, coordinates_n_y, coordinates_n_z, n_containment, n_food_k, n_strong_k, n_mid_k, coordinates_z_x, coordinates_z_y, coordinates_z_z, z_containment, z_food_k, z_strong_k, z_mid_k, coordinates_m_x, coordinates_m_y, coordinates_m_z, m_containment, m_food_k, m_strong_k, m_mid_k, coordinates_x_x, coordinates_x_y, coordinates_x_z, x_containment, x_food_k, x_strong_k, x_mid_k, coordinates_b_x, coordinates_b_y, coordinates_b_z, b_containment, b_food_k, b_strong_k, b_mid_k, coordinates_d_x, coordinates_d_y, coordinates_d_z, d_containment, d_food_k, d_strong_k, d_mid_k, coordinates_l_x, coordinates_l_y, coordinates_l_z, l_containment, l_food_k, l_strong_k, l_mid_k, coordinates_a_x, coordinates_a_y, coordinates_a_z, a_containment, a_food_k, a_strong_k, a_mid_k, coordinates_h_x, coordinates_h_y, coordinates_h_z, h_containment, h_food_k, h_strong_k, h_mid_k, coordinates_q_x, coordinates_q_y, coordinates_q_z, q_containment, q_food_k, q_strong_k, q_mid_k in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/next_obj_classifier_2022-03-23/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/next_obj_classifier_2022-03-23/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('models/next_obj_classifier_2022-03-23')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e33c5a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "reloaded_model = tf.keras.models.load_model('models/next_obj_classifier_2022-03-23')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a6bfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test prediction for one sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b50493d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df.loc[0].drop('target').to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63d9fe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dict = {name: tf.convert_to_tensor([value]) for name, value in sample.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e68164e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reloaded_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_40686/2370999569.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreloaded_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'reloaded_model' is not defined"
     ]
    }
   ],
   "source": [
    "prediction = reloaded_model.predict(input_dict)\n",
    "prediction = tf.nn.sigmoid(prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad905aed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "27161320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'p'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get label for prediction\n",
    "\n",
    "pred_label = labels[np.argmax(prediction)]\n",
    "pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ae9f505d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prequential_error(dataframe, model, labels, nr_of_sequences):\n",
    "    errors = [[] for seq in range(0, nr_of_sequences + 1)]\n",
    "    start_token_count = 0\n",
    "    sequence_nr = 0\n",
    "    \n",
    "    for row in range(0, len(dataframe)): \n",
    "        observed_target = dataframe.loc[row, 'target']\n",
    "        sample = dataframe.loc[row].drop('target').to_dict()\n",
    "        input_dict = {name: tf.convert_to_tensor([value]) for name, value in \n",
    "                          sample.items()}\n",
    "        predicted_target = model.predict(input_dict)\n",
    "        predicted_target = tf.nn.sigmoid(predicted_target[0])\n",
    "            \n",
    "        pred_label = labels[np.argmax(predicted_target)]\n",
    "        error = 1 - damerauLevenshtein(pred_label, observed_target)\n",
    "        errors[sequence_nr].append(error)\n",
    "        \n",
    "        if row != 0 and dataframe.loc[row, 'input'] == '<start>':\n",
    "            start_token_count += 1\n",
    "        \n",
    "        if start_token_count > 0:\n",
    "            sequence_nr += 1\n",
    "            start_token_count = 0\n",
    "            \n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d7ae2385",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = get_prequential_error(df, model, labels, nr_of_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c3eacff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "summed_error = [sum(error) for error in errors[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "28e4a79e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(summed_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9edef143",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('results/nn_spatialinfo_prequential_summed_2022-04-14.txt', 'w') as file:\n",
    "#    file.write(str(summed_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cf9a2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.7",
   "language": "python",
   "name": "tf2.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
